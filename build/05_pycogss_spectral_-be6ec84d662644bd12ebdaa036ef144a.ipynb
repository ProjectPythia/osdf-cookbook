{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b21c4c4a-352a-4981-b994-c3bd9057d533",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "# import s3fs\n",
    "import re\n",
    "from pelicanfs.core import PelicanFileSystem, PelicanMap,OSDFFileSystem \n",
    "# import fsspec.implementations.http as fshttp\n",
    "import geopandas as gpd\n",
    "from pystac_client import Client\n",
    "# from odc.stac import stac_load\n",
    "from rasterio.mask import mask\n",
    "import rasterio\n",
    "from shapely.geometry import box\n",
    "from urllib.parse import urlparse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "575c1cf8-98a4-4861-94ba-284ff9f16dcf",
   "metadata": {},
   "outputs": [],
   "source": [
    "import dask \n",
    "from dask_jobqueue import PBSCluster\n",
    "from dask.distributed import Client as dask_client\n",
    "from dask.distributed import performance_report"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db4dfbf2-7cc0-4322-b3b9-c3e7cf3c0c37",
   "metadata": {},
   "source": [
    "### Use the GeoJSON file to get the Area of Interest and query the STAC catalog for items"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "022a5bd5-95f2-4ce3-951b-ea2f97682614",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                     id  SUB_AREA  COAST     PFAF_ID  DIST_MAIN    HYBAS_ID  \\\n",
      "0  00140000000000002983     128.1      0  3512704524      784.3  3100180240   \n",
      "\n",
      "   DIST_SINK   NEXT_DOWN  ORDER  ENDO    MAIN_BAS   NEXT_SINK   SORT  UP_AREA  \\\n",
      "0      784.3  3100180230      4     0  3100009670  3100009670  66318    128.1   \n",
      "\n",
      "                                            geometry  \n",
      "0  POLYGON ((134.51667 66.87917, 134.51752 66.875...  \n"
     ]
    }
   ],
   "source": [
    "# Load the GeoJSON file\n",
    "geojson_path = '3100180240.geojson' \n",
    "gdf = gpd.read_file(geojson_path)\n",
    "\n",
    "# Display the loaded GeoDataFrame\n",
    "print(gdf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "503a37c8-1e88-423e-99e8-7a3bce851f9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Bounding Box: (134.51666686838126, 66.7708333115583, 134.9046488751149, 66.97083294070578)\n"
     ]
    }
   ],
   "source": [
    "# Extract AOI geometry\n",
    "aoi_geometry = gdf.geometry.iloc[0]\n",
    "aoi_bounds   = aoi_geometry.bounds  # (minx, miny, maxx, maxy)\n",
    "\n",
    "# Get AOI centroid for visualization\n",
    "centroid  = aoi_geometry.centroid\n",
    "long, lat = centroid.x, centroid.y\n",
    "\n",
    "# Print the bounding box to verify\n",
    "print(\"Bounding Box:\", aoi_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "17db5b4b-7a8b-4515-b9d4-809cf4a6fc2d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 258 matching items.\n"
     ]
    }
   ],
   "source": [
    "# Connect to the Earth Search STAC API (Sentinel-2 Level-2A COGs are available here)\n",
    "catalog_url = \"https://earth-search.aws.element84.com/v1\"\n",
    "catalog     = Client.open(catalog_url)\n",
    "\n",
    "# Define the date range as strings\n",
    "start_date      = \"2019-01\"\n",
    "end_date        = \"2023-02\"\n",
    "\n",
    "# Define cloud cover threshold\n",
    "cloud_cover_max = 0.05  # 5% cloud cover threshold\n",
    "#cloud_cover_max = 0.20  # 20% cloud cover threshold\n",
    "\n",
    "# Perform the search\n",
    "search = catalog.search(\n",
    "                 collections=[\"sentinel-2-l2a\"],\n",
    "                 bbox=aoi_bounds,\n",
    "                 datetime=f\"{start_date}/{end_date}\",\n",
    "                 #datetime=\"2022-06-01/2022-09-30\",\n",
    "                 query={\"eo:cloud_cover\": {\"lt\": cloud_cover_max * 100}}\n",
    "                )\n",
    "\n",
    "# Get all matching items\n",
    "items = list(search.items())\n",
    "print(f\"Found {len(items)} matching items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7b5623bb-6410-4bd9-8614-a94b1b338e20",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Item 1: S2B_53WMQ_20230222_0_L2A\n",
      "  aot: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/AOT.tif\n",
      "  blue: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/B02.tif\n",
      "  coastal: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/B01.tif\n",
      "  granule_metadata: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/granule_metadata.xml\n",
      "  green: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/B03.tif\n",
      "  nir: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/B08.tif\n",
      "  nir08: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/B8A.tif\n",
      "  nir09: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/B09.tif\n",
      "  red: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/B04.tif\n",
      "  rededge1: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/B05.tif\n",
      "  rededge2: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/B06.tif\n",
      "  rededge3: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/B07.tif\n",
      "  scl: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/SCL.tif\n",
      "  swir16: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/B11.tif\n",
      "  swir22: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/B12.tif\n",
      "  thumbnail: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/thumbnail.jpg\n",
      "  tileinfo_metadata: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/tileinfo_metadata.json\n",
      "  visual: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/TCI.tif\n",
      "  wvp: https://sentinel-cogs.s3.us-west-2.amazonaws.com/sentinel-s2-l2a-cogs/53/W/MQ/2023/2/S2B_53WMQ_20230222_0_L2A/WVP.tif\n",
      "  aot-jp2: s3://sentinel-s2-l2a/tiles/53/W/MQ/2023/2/22/0/AOT.jp2\n",
      "  blue-jp2: s3://sentinel-s2-l2a/tiles/53/W/MQ/2023/2/22/0/B02.jp2\n",
      "  coastal-jp2: s3://sentinel-s2-l2a/tiles/53/W/MQ/2023/2/22/0/B01.jp2\n",
      "  green-jp2: s3://sentinel-s2-l2a/tiles/53/W/MQ/2023/2/22/0/B03.jp2\n",
      "  nir-jp2: s3://sentinel-s2-l2a/tiles/53/W/MQ/2023/2/22/0/B08.jp2\n",
      "  nir08-jp2: s3://sentinel-s2-l2a/tiles/53/W/MQ/2023/2/22/0/B8A.jp2\n",
      "  nir09-jp2: s3://sentinel-s2-l2a/tiles/53/W/MQ/2023/2/22/0/B09.jp2\n",
      "  red-jp2: s3://sentinel-s2-l2a/tiles/53/W/MQ/2023/2/22/0/B04.jp2\n",
      "  rededge1-jp2: s3://sentinel-s2-l2a/tiles/53/W/MQ/2023/2/22/0/B05.jp2\n",
      "  rededge2-jp2: s3://sentinel-s2-l2a/tiles/53/W/MQ/2023/2/22/0/B06.jp2\n",
      "  rededge3-jp2: s3://sentinel-s2-l2a/tiles/53/W/MQ/2023/2/22/0/B07.jp2\n",
      "  scl-jp2: s3://sentinel-s2-l2a/tiles/53/W/MQ/2023/2/22/0/SCL.jp2\n",
      "  swir16-jp2: s3://sentinel-s2-l2a/tiles/53/W/MQ/2023/2/22/0/B11.jp2\n",
      "  swir22-jp2: s3://sentinel-s2-l2a/tiles/53/W/MQ/2023/2/22/0/B12.jp2\n",
      "  visual-jp2: s3://sentinel-s2-l2a/tiles/53/W/MQ/2023/2/22/0/TCI.jp2\n",
      "  wvp-jp2: s3://sentinel-s2-l2a/tiles/53/W/MQ/2023/2/22/0/WVP.jp2\n"
     ]
    }
   ],
   "source": [
    "# Confirm that the matching items are hosted in a aws-us-region by printing out the href links for the first n items\n",
    "n=1\n",
    "\n",
    "for i, item in enumerate(items[:n]):\n",
    "    print(f\"\\nItem {i+1}: {item.id}\")\n",
    "    for asset_key, asset in item.assets.items():\n",
    "        print(f\"  {asset_key}: {asset.href}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c48c5edd-09ba-4ae8-be72-7892d73eb297",
   "metadata": {},
   "outputs": [],
   "source": [
    "from shapely.geometry import mapping\n",
    "\n",
    "# Reproject AOI to match raster CRS\n",
    "from pyproj import CRS\n",
    "from geopandas import GeoSeries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3f08fc53-d11f-4e0d-a2da-734cdb903ba8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def returnOSDFPath(url):\n",
    "    \"\"\"\n",
    "    Converts a URL to an OSDF path.\n",
    "\n",
    "    Parameters:\n",
    "    - url: URL to convert.\n",
    "\n",
    "    Returns:\n",
    "    - OSDF path.\n",
    "    \"\"\"\n",
    "    # Parse the URL\n",
    "    parsed_url = urlparse(url)\n",
    "    \n",
    "    # Construct the OSDF path\n",
    "    osdf_path = f\"/aws-opendata/us-west-2/sentinel-cogs{parsed_url.path}\"\n",
    "    \n",
    "    return osdf_path\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d372a90-bba5-4c58-861a-a3f0f3588316",
   "metadata": {},
   "source": [
    "### Apply various masks and calculate NDVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f3c86952-efe2-4f37-b422-88e308808048",
   "metadata": {},
   "outputs": [],
   "source": [
    "def clp(image_src, aoi_geometry):\n",
    "    \"\"\"\n",
    "    Clip a raster image to the Area of Interest (AOI).\n",
    "\n",
    "    Parameters:\n",
    "    - image_src: Open rasterio dataset.\n",
    "    - aoi_geometry: AOI geometry as a GeoJSON-like object.\n",
    "\n",
    "    Returns:\n",
    "    - Clipped image array and updated metadata.\n",
    "    \"\"\"\n",
    "    # out_image, out_transform = mask(image_src, [aoi_geometry], crop=True)\n",
    "    out_image, out_transform = mask(image_src, aoi_geometry, crop=True)\n",
    "    out_meta = image_src.meta.copy()\n",
    "    out_meta.update({\n",
    "        \"driver\": \"GTiff\",\n",
    "        \"height\": out_image.shape[1],\n",
    "        \"width\": out_image.shape[2],\n",
    "        \"transform\": out_transform\n",
    "    })\n",
    "    return out_image, out_meta\n",
    "\n",
    "def maskWater(image, water_mask):\n",
    "    \"\"\"\n",
    "    Masks out water pixels using the MODIS water mask.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Raster image to mask.\n",
    "    - water_mask: Water mask raster.\n",
    "\n",
    "    Returns:\n",
    "    - Water-masked image.\n",
    "    \"\"\"\n",
    "    water = water_mask.read(1)  # Read the water mask\n",
    "    mask = water < 1  # Mask water pixels (water < 1)\n",
    "    image_masked = np.where(mask, image, np.nan)\n",
    "    return image_masked\n",
    "\n",
    "def maskS2snow(image, snow_prob):\n",
    "    \"\"\"\n",
    "    Masks snow pixels using the MSK_SNWPRB (Snow Probability Mask).\n",
    "\n",
    "    Parameters:\n",
    "    - image: Raster image to mask.\n",
    "    - snow_prob: Snow probability raster.\n",
    "\n",
    "    Returns:\n",
    "    - Snow-masked image.\n",
    "    \"\"\"\n",
    "    snow = snow_prob.read(1)  # Read the snow probability mask\n",
    "    mask = snow < 0.009  # Mask snow pixels (snow probability < 0.9%)\n",
    "    image_masked = np.where(mask, image, np.nan)\n",
    "    return image_masked\n",
    "\n",
    "def maskWhite(image, b2, b3, b4):\n",
    "    \"\"\"\n",
    "    Masks white pixels by converting RGB to grayscale and applying a threshold.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Raster image to mask.\n",
    "    - b2, b3, b4: Blue, Green, and Red bands respectively.\n",
    "\n",
    "    Returns:\n",
    "    - Grayscale-masked image.\n",
    "    \"\"\"\n",
    "    # Convert RGB to grayscale\n",
    "    grayscale = (0.3 * b4.read(1) + 0.59 * b3.read(1) + 0.11 * b2.read(1)) * 1e4\n",
    "    mask = grayscale <= 2000  # Mask white pixels (grayscale > 2000)\n",
    "    image_masked = np.where(mask, image, np.nan)\n",
    "    return image_masked"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37b8135b-1924-4a0f-b5db-bcd5169633e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing dataset #1\n",
      "Dataset #1 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #2\n",
      "Dataset #2 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #3\n",
      "Dataset #3 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #4\n",
      "Dataset #4 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #5\n",
      "Dataset #5 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #6\n",
      "Dataset #6 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #7\n",
      "Dataset #7 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #8\n",
      "Dataset #8 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #9\n",
      "Dataset #9 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #10\n",
      "Dataset #10 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #11\n",
      "Dataset #11 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #12\n",
      "Dataset #12 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #13\n",
      "Dataset #13 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #14\n",
      "Dataset #14 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #15\n",
      "Dataset #15 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #16\n",
      "Dataset #16 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #17\n",
      "Dataset #17 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #18\n",
      "Dataset #18 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #19\n",
      "Dataset #19 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #20\n",
      "Dataset #20 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #21\n",
      "Dataset #21 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #22\n",
      "Dataset #22 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #23\n",
      "Dataset #23 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #24\n",
      "Dataset #24 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #25\n",
      "Dataset #25 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #26\n",
      "Dataset #26 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #27\n",
      "Dataset #27 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #28\n",
      "Dataset #28 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #29\n",
      "Dataset #29 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #30\n",
      "Dataset #30 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #31\n",
      "Dataset #31 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #32\n",
      "Dataset #32 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #33\n",
      "Dataset #33 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #34\n",
      "Dataset #34 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #35\n",
      "Dataset #35 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #36\n",
      "Dataset #36 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #37\n",
      "Dataset #37 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #38\n",
      "Dataset #38 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #39\n",
      "Dataset #39 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #40\n",
      "Dataset #40 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #41\n",
      "Dataset #41 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #42\n",
      "Dataset #42 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #43\n",
      "Dataset #43 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #44\n",
      "Dataset #44 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #45\n",
      "Dataset #45 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #46\n",
      "Dataset #46 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #47\n",
      "Dataset #47 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #48\n",
      "Dataset #48 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #49\n",
      "Dataset #49 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #50\n",
      "Dataset #50 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #51\n",
      "Dataset #51 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #52\n",
      "Dataset #52 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #53\n",
      "Dataset #53 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #54\n",
      "Dataset #54 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #55\n",
      "Dataset #55 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #56\n",
      "Dataset #56 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #57\n",
      "Dataset #57 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #58\n",
      "Dataset #58 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #59\n",
      "Dataset #59 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #60\n",
      "Dataset #60 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #61\n",
      "Dataset #61 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #62\n",
      "Dataset #62 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #63\n",
      "Dataset #63 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #64\n",
      "Dataset #64 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #65\n",
      "Dataset #65 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #66\n",
      "Dataset #66 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #67\n",
      "Dataset #67 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #68\n",
      "Dataset #68 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #69\n",
      "Dataset #69 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #70\n",
      "Dataset #70 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #71\n",
      "Dataset #71 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #72\n",
      "Dataset #72 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #73\n",
      "Dataset #73 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #74\n",
      "Dataset #74 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #75\n",
      "Dataset #75 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #76\n",
      "Dataset #76 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #77\n",
      "Dataset #77 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #78\n",
      "Dataset #78 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #79\n",
      "Dataset #79 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #80\n",
      "Dataset #80 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #81\n",
      "Dataset #81 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #82\n",
      "Dataset #82 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #83\n",
      "Dataset #83 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #84\n",
      "Dataset #84 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #85\n",
      "Dataset #85 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #86\n",
      "Dataset #86 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #87\n",
      "Dataset #87 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #88\n",
      "Dataset #88 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #89\n",
      "Dataset #89 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #90\n",
      "Dataset #90 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #91\n",
      "Dataset #91 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #92\n",
      "Dataset #92 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #93\n",
      "Dataset #93 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #94\n",
      "Dataset #94 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #95\n",
      "Dataset #95 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #96\n",
      "Dataset #96 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #97\n",
      "Dataset #97 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #98\n",
      "Dataset #98 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #99\n",
      "Dataset #99 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #100\n",
      "Dataset #100 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #101\n",
      "Dataset #101 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #102\n",
      "Dataset #102 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #103\n",
      "Dataset #103 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #104\n",
      "Dataset #104 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #105\n",
      "Dataset #105 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #106\n",
      "Dataset #106 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #107\n",
      "Dataset #107 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #108\n",
      "Dataset #108 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #109\n",
      "Dataset #109 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #110\n",
      "Dataset #110 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #111\n",
      "Dataset #111 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #112\n",
      "Dataset #112 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #113\n",
      "Dataset #113 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #114\n",
      "Dataset #114 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #115\n",
      "Dataset #115 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #116\n",
      "Dataset #116 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #117\n",
      "Dataset #117 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #118\n",
      "Dataset #118 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #119\n",
      "Dataset #119 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #120\n",
      "Dataset #120 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #121\n",
      "Dataset #121 processed. Ready for visualization or further analysis.\n",
      "Processing dataset #122\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Loop through each item in the STAC query\n",
    "for idx, item in enumerate(items, start=1):\n",
    "    print(f\"Processing dataset #{idx}\")\n",
    "\n",
    "    # Check required assets\n",
    "    required_assets = [\"red\", \"green\", \"blue\", \"scl\"]\n",
    "    if not all(asset in item.assets for asset in required_assets):\n",
    "        print(f\"Skipping dataset #{idx}: Missing required assets.\")\n",
    "        continue\n",
    "\n",
    "    # Get asset URLs\n",
    "    red_url = item.assets[\"red\"].href\n",
    "    green_url = item.assets[\"green\"].href\n",
    "    blue_url = item.assets[\"blue\"].href\n",
    "    scl_url = item.assets[\"scl\"].href\n",
    "\n",
    "    # Reproject AOI to match raster CRS\n",
    "    with rasterio.open(red_url) as src:\n",
    "        raster_crs = CRS(src.crs)\n",
    "    aoi_geometry_reprojected = GeoSeries(aoi_geometry).set_crs(gdf.crs).to_crs(raster_crs)\n",
    "\n",
    "    # Open and clip bands\n",
    "    with rasterio.open(red_url) as red_src, \\\n",
    "        rasterio.open(green_url) as green_src, \\\n",
    "        rasterio.open(blue_url) as blue_src, \\\n",
    "        rasterio.open(scl_url) as scl_src:\n",
    "\n",
    "        aoi_geometry_reprojected = GeoSeries(aoi_geometry).set_crs(gdf.crs).to_crs(raster_crs)\n",
    "        raster_bounds = box(*red_src.bounds)\n",
    "\n",
    "        if not aoi_geometry_reprojected[0].intersects(raster_bounds):\n",
    "            print(f\"Warning: AOI does not intersect the bounds of {red_url}. Skipping.\")\n",
    "            continue\n",
    "\n",
    "        # Clip all RGB and SCL bands to AOI\n",
    "        red_clipped, red_meta = clp(red_src, aoi_geometry_reprojected)\n",
    "        green_clipped, _      = clp(green_src, aoi_geometry_reprojected)\n",
    "        blue_clipped, _       = clp(blue_src, aoi_geometry_reprojected)\n",
    "        scl_clipped, _        = clp(scl_src, aoi_geometry_reprojected)\n",
    "\n",
    "        # # Clip water_mask if available\n",
    "        # if water_mask_available:\n",
    "        #     with rasterio.open(water_mask_url) as water_mask_src:\n",
    "        #         water_mask_clipped, _ = clp(water_mask_src, aoi_geometry_reprojected)\n",
    "\n",
    "        # Apply maskS2clouds\n",
    "        # red_masked = maskS2clouds(red_clipped, scl_clipped)\n",
    "        # green_masked = maskS2clouds(green_clipped, scl_clipped)\n",
    "        # blue_masked = maskS2clouds(blue_clipped, scl_clipped)\n",
    "\n",
    "        # # Apply maskWater if available\n",
    "        # if water_mask_available:\n",
    "        #     red_masked = maskWater(red_masked, water_mask_clipped)\n",
    "        #     green_masked = maskWater(green_masked, water_mask_clipped)\n",
    "        #     blue_masked = maskWater(blue_masked, water_mask_clipped)\n",
    "\n",
    "        # # Apply maskWhite\n",
    "        # red_final = maskWhite(red_clipped, blue_clipped, green_clipped, red_clipped)\n",
    "        # green_final = maskWhite(green_clipped, blue_clipped, green_clipped, red_clipped)\n",
    "        # blue_final = maskWhite(blue_clipped, blue_clipped, green_clipped, red_clipped)\n",
    "\n",
    "        print(f\"Dataset #{idx} processed. Ready for visualization or further analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed795a3d-f66f-4a0f-a440-d0bc6e0321b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%time\n",
    "# # Using pelicanfs\n",
    "# # Loop through each item in the STAC query\n",
    "# for idx, item in enumerate(items, start=1):\n",
    "#     print(f\"Processing dataset #{idx}\")\n",
    "\n",
    "#     # Check required assets\n",
    "#     required_assets = [\"red\", \"green\", \"blue\", \"scl\"]\n",
    "#     if not all(asset in item.assets for asset in required_assets):\n",
    "#         print(f\"Skipping dataset #{idx}: Missing required assets.\")\n",
    "#         continue\n",
    "\n",
    "#     # Get asset URLs\n",
    "#     red_url = item.assets[\"red\"].href\n",
    "#     green_url = item.assets[\"green\"].href\n",
    "#     blue_url = item.assets[\"blue\"].href\n",
    "#     scl_url = item.assets[\"scl\"].href\n",
    "\n",
    "#     pel_red_url   = returnOSDFPath(red_url)\n",
    "#     pel_green_url = returnOSDFPath(green_url)\n",
    "#     pel_blue_url  = returnOSDFPath(blue_url)\n",
    "#     pel_scl_url   = returnOSDFPath(scl_url)\n",
    "\n",
    "#     pelfs = PelicanFileSystem(\"pelican://osg-htc.org\")\n",
    "\n",
    "    # # Reproject AOI to match raster CRS\n",
    "    # with rasterio.open(pel_red_url,opener=pelfs) as src:\n",
    "    # with rasterio.open(red_url) as src:\n",
    "    #     raster_crs = CRS(src.crs)\n",
    "    # aoi_geometry_reprojected = GeoSeries(aoi_geometry).set_crs(gdf.crs).to_crs(raster_crs)\n",
    "\n",
    "    # # Reproject AOI to match raster CRS\n",
    "    # with rasterio.open(pel_red_url, opener=pelfs) as red_src, \\\n",
    "    #      rasterio.open(pel_green_url, opener=pelfs) as green_src, \\\n",
    "    #      rasterio.open(pel_blue_url, opener=pelfs) as blue_src, \\\n",
    "    #      rasterio.open(pel_scl_url, opener=pelfs) as scl_src:\n",
    "\n",
    "    #     aoi_geometry_reprojected = GeoSeries(aoi_geometry).set_crs(gdf.crs).to_crs(raster_crs)\n",
    "    #     raster_bounds = box(*red_src.bounds)\n",
    "\n",
    "    #     if not aoi_geometry_reprojected[0].intersects(raster_bounds):\n",
    "    #         print(f\"Warning: AOI does not intersect the bounds of {red_url}. Skipping.\")\n",
    "    #         continue\n",
    "\n",
    "    #     # Clip all RGB and SCL bands to AOI\n",
    "    #     red_clipped, red_meta = clp(red_src, aoi_geometry_reprojected)\n",
    "    #     green_clipped, _      = clp(green_src, aoi_geometry_reprojected)\n",
    "    #     blue_clipped, _       = clp(blue_src, aoi_geometry_reprojected)\n",
    "    #     scl_clipped, _        = clp(scl_src, aoi_geometry_reprojected)\n",
    "\n",
    "    #     print(f\"Dataset #{idx} processed. Ready for visualization or further analysis.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "218ce0b6-46fd-4d96-bd0b-a3ba05e6fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "# Function to scale image bands properly\n",
    "def scale_band(band):\n",
    "    scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "    return scaler.fit_transform(band)  # Normalize between 0-1\n",
    "\n",
    "# Assuming red_clipped, green_clipped, and blue_clipped are 2D NumPy arrays\n",
    "rgb = np.dstack((scale_band(red_clipped.squeeze()),\n",
    "    scale_band(green_clipped.squeeze()),\n",
    "    scale_band(blue_clipped.squeeze()),\n",
    "))\n",
    "\n",
    "# Plot\n",
    "plt.figure(figsize=(10, 8))\n",
    "plt.imshow(rgb)\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9103c38-109a-4f76-a970-f7658a53d98b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def visualize_rgb(red_band, green_band, blue_band, title=\"RGB Composite\"):\n",
    "#     \"\"\"\n",
    "#     Visualizes an RGB composite of raster bands using matplotlib.\n",
    "\n",
    "#     Parameters:\n",
    "#     - red_band, green_band, blue_band (numpy array): Red, Green, and Blue bands.\n",
    "#     - title (str): Title for the plot.\n",
    "#     \"\"\"\n",
    "#     rgb = np.dstack((\n",
    "#         np.clip(red_band, 0, 1),  # Normalize reflectance between 0-1\n",
    "#         np.clip(green_band, 0, 1),\n",
    "#         np.clip(blue_band, 0, 1)\n",
    "#     ))\n",
    "#     plt.figure(figsize=(10, 8))\n",
    "#     plt.imshow(rgb)\n",
    "#     plt.title(title)\n",
    "#     plt.axis(\"off\")\n",
    "#     plt.show()\n",
    "\n",
    "# # Example: Visualize RGB composite\n",
    "# visualize_rgb(red_clipped, green_clipped, blue_clipped, title=\"Processed RGB Composite\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python:osdf",
   "language": "python",
   "name": "osdf"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
