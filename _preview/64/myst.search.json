{"version":"1","records":[{"hierarchy":{"lvl1":"OSDF Cookbook"},"type":"lvl1","url":"/","position":0},{"hierarchy":{"lvl1":"OSDF Cookbook"},"content":"\n\n\n\n\n\n\n\n\n\nThis Project Pythia Cookbook covers using the Open Science Data Federation (OSDF), a service for streaming scientific data across the globe.","type":"content","url":"/","position":1},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl2":"Motivation"},"type":"lvl2","url":"/#motivation","position":2},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl2":"Motivation"},"content":"Have you ever been frustrated by the complications of accessing scientific data?  Why can’t it “just work”, like watching a Netflix movie?\n\nThe OSDF is a service that simplifies the streaming of a wide range of scientific datasets with a goal that data access “just works”.  It\nis meant to improve data availability for researchers working at any scale from individual laptops to distributed computing services\nsuch as the OSG’s \n\nOSPool.\n\nThis cookbook gives motivating use cases from the geoscience community, including using datasets from NSF NCAR’s \n\nResearch Data Archive (RDA) and the datasets of AWS \n\nOpenData.","type":"content","url":"/#motivation","position":3},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl2":"Authors"},"type":"lvl2","url":"/#authors","position":4},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl2":"Authors"},"content":"Harsha R. Hampapura\n\n\nBrian Bockelman\n\n\nAlexander Hoelzeman\n\n\nEmma Turetsky\n\n\nAmandha Wingert Barok\n\n\nAashish Panta\n\n\nJustin Hiemstra\n\n\nDouglas Schuster\n\n\nRiley Conroy\n\n\nKibiwott Koech","type":"content","url":"/#authors","position":5},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl3":"Contributors","lvl2":"Authors"},"type":"lvl3","url":"/#contributors","position":6},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl3":"Contributors","lvl2":"Authors"},"content":"","type":"content","url":"/#contributors","position":7},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl2":"Structure"},"type":"lvl2","url":"/#structure","position":8},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl2":"Structure"},"content":"This cookbook is broken up into two pieces - some background knowledge on the OSDF service itself\nand then a series of motivating examples from different repositories accessible via the OSDF.","type":"content","url":"/#structure","position":9},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl3":"OSDF Fundamentals","lvl2":"Structure"},"type":"lvl3","url":"/#osdf-fundamentals","position":10},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl3":"OSDF Fundamentals","lvl2":"Structure"},"content":"What is the OSDF?  Who supports it? How can it benefit from my science?  A dive into the infrastructure itself.","type":"content","url":"/#osdf-fundamentals","position":11},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl3":"Using Datasets from NCAR’s Research Data Archive","lvl2":"Structure"},"type":"lvl3","url":"/#using-datasets-from-ncars-research-data-archive","position":12},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl3":"Using Datasets from NCAR’s Research Data Archive","lvl2":"Structure"},"content":"NSF NCAR’s \n\nResearch Data Archive (RDA) contains a large collection of meteorological, atmospheric composition, and oceanographic observations, and operational and reanalysis model outputs, integrated with NSF NCAR High Performance Compute services to support atmospheric and geosciences research. This chapter demonstrates how to use common data science tools when streaming from the RDA.","type":"content","url":"/#using-datasets-from-ncars-research-data-archive","position":13},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl3":"Using Datasets from FIU’s Envistor","lvl2":"Structure"},"type":"lvl3","url":"/#using-datasets-from-fius-envistor","position":14},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl3":"Using Datasets from FIU’s Envistor","lvl2":"Structure"},"content":"Florida International University (FIU) runs the \n\nEnvistor project, aggregating climate datasets from the south Florida region.","type":"content","url":"/#using-datasets-from-fius-envistor","position":15},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl3":"Using NOAA’s SONAR Fisheries Datasets","lvl2":"Structure"},"type":"lvl3","url":"/#using-noaas-sonar-fisheries-datasets","position":16},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl3":"Using NOAA’s SONAR Fisheries Datasets","lvl2":"Structure"},"content":"NOAA maintains a copy of its SONAR-based datasets of Atlanta fisheries data in the popular Zarr format.  This chapter shows how to load and use the datasets and fuse it with other products.","type":"content","url":"/#using-noaas-sonar-fisheries-datasets","position":17},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl3":"Using Sentinel Data from AWS","lvl2":"Structure"},"type":"lvl3","url":"/#using-sentinel-data-from-aws","position":18},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl3":"Using Sentinel Data from AWS","lvl2":"Structure"},"content":"All of AWS OpenData is connected to the OSDF!  This chapter includes examples of streaming Sentinel-2 data, stored in AWS’s OpenData program, to your notebook.","type":"content","url":"/#using-sentinel-data-from-aws","position":19},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl2":"Running the Notebooks"},"type":"lvl2","url":"/#running-the-notebooks","position":20},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl2":"Running the Notebooks"},"content":"You can either run the notebook using \n\nBinder or on your local machine.","type":"content","url":"/#running-the-notebooks","position":21},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-binder","position":22},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl3":"Running on Binder","lvl2":"Running the Notebooks"},"content":"The simplest way to interact with a Jupyter Notebook is through\n\n\nBinder, which enables the execution of a\n\n\nJupyter Book in the cloud. The details of how this works are not\nimportant for now. All you need to know is how to launch a Pythia\nCookbooks chapter via Binder. Simply navigate your mouse to\nthe top right corner of the book chapter you are viewing and click\non the rocket ship icon, (see figure below), and be sure to select\n“launch Binder”. After a moment you should be presented with a\nnotebook that you can interact with. I.e. you’ll be able to execute\nand even change the example programs. You’ll see that the code cells\nhave no output at first, until you execute them by pressing\nShift+Enter. Complete details on how to interact with\na live Jupyter notebook are described in \n\nGetting Started with\nJupyter.\n\nNote, not all Cookbook chapters are executable. If you do not see\nthe rocket ship icon, such as on this page, you are not viewing an\nexecutable book chapter.","type":"content","url":"/#running-on-binder","position":23},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"type":"lvl3","url":"/#running-on-your-own-machine","position":24},{"hierarchy":{"lvl1":"OSDF Cookbook","lvl3":"Running on Your Own Machine","lvl2":"Running the Notebooks"},"content":"If you are interested in running this material locally on your computer, you will need to follow this workflow:\n\nClone the https://github.com/ProjectPythia/osdf-cookbook repository: git clone https://github.com/ProjectPythia/osdf-cookbook.git\n\nMove into the osdf-cookbook directorycd osdf-cookbook\n\nCreate and activate your conda environment from the environment.yml fileconda env create -f environment.yml\nconda activate osdf-cookbook\n\nMove into the notebooks directory and start up Jupyterlabcd notebooks/\njupyter lab","type":"content","url":"/#running-on-your-own-machine","position":25},{"hierarchy":{"lvl1":"Streaming Data with the Open Science Data Federation (OSDF)"},"type":"lvl1","url":"/notebooks/osdf-intro","position":0},{"hierarchy":{"lvl1":"Streaming Data with the Open Science Data Federation (OSDF)"},"content":"Have you ever pondered why accessing large-scale scientific data is so complicated, while accessing large-scale volumes of movies is so simple on Netflix?\n\nEach data repository has its own website or a set of unique tools for accessing data.  Users are often encouraged to download datasets locally and then do local computations, as repositories prioritize long-term storage and preservation rather than fast or distributed access.\n\nHow does Netflix do it without making you download the whole movie ahead of time?  They leverage a content distribution network (CDN), which caches copies of the most popular movies at opportune locations on the Internet closer to users. They also let you stream your favorite shows so you can start watching while later sections of the show are still downloading.\n\nThe \n\nOSDF, an NSF-funded infrastructure providing a CDN for science, makes this kind of streaming possible for scientific data.  It is connected to popular open science repositories and has hardware embedded across US and international networks and at large computing sites.\n\nThis cookbook provides examples of using the OSDF’s streaming to power science use cases in earth sciences.","type":"content","url":"/notebooks/osdf-intro","position":1},{"hierarchy":{"lvl1":"Streaming Data with the Open Science Data Federation (OSDF)","lvl2":"Do First, Understand Later"},"type":"lvl2","url":"/notebooks/osdf-intro#do-first-understand-later","position":2},{"hierarchy":{"lvl1":"Streaming Data with the Open Science Data Federation (OSDF)","lvl2":"Do First, Understand Later"},"content":"How Do You Use the OSDF?\n\nThe service is powered by the same protocol as the web, HTTPS.  Thus, the simplest use case is to download an object by using the browser.\n\nClick on this link:\n\nhttps://​osdf​-director​.osg​-htc​.org​/ospool​/uc​-shared​/public​/OSG​-Staff​/validation​/test​.txt\n\nIf a new tab opened with the text “Hello, World” – congratulations, you used the OSDF!\n\nOSDF is often used in conjunction with computing workflows and downloads occur as part of a script.  For this, a command line client - \n\npelican is utilized.  Try running the following:\n\npelican object get osdf:///routeviews/chicago/route-views.chicago/bgpdata/2025.03/RIBS/rib.20250319.0400.bz2 ./\n\nDepending on the speed of your Internet connection, you may see a progress bar as the download proceeds.\n\nCongratulations, you’re now the proud owner of 72MB of Internet routing data!\n\nFor both of these cases, we downloaded the entire object.  What happens if the dataset contains data for the entire planet but you are only interested in the state of Nebraska?  It’s more effective to stream the subset.  For that, we will use the \n\nPelican Python library; this library will be used throughout the remaining chapters of this cookbook.","type":"content","url":"/notebooks/osdf-intro#do-first-understand-later","position":3},{"hierarchy":{"lvl1":"Streaming Data with the Open Science Data Federation (OSDF)","lvl2":"About the OSDF"},"type":"lvl2","url":"/notebooks/osdf-intro#about-the-osdf","position":4},{"hierarchy":{"lvl1":"Streaming Data with the Open Science Data Federation (OSDF)","lvl2":"About the OSDF"},"content":"You don’t need to know how Netflix is built to press “play”.  Similarly, you don’t need to understand the guts of the OSDF to use it in your science.  However, a few key concepts are useful!\n\nOSDF Infrastructure: The map below shows the distributed pieces of the OSDF:\n\nEach “O” on the map is an origin; the origin service connects an existing repository to the OSDF service, making some datasets available and protecting the repository from overload.  Origins are typically placed nearby where the data lives; the origin for the NCAR Research Data Archive (RDA) is in the same datacenter as the RDA.\n\nEach “C” is a cache.  The cache makes temporary copies of objects upon access so, on subsequent accesses, the object comes from the cache and not from the repository.  This reduces the load on the repository and, ideally, increases scalability.\n\nUnified Namespace: The OSDF provides a unified namespace for all available objects.  Each repository receives a unique prefix (the IceCube experiment’s data is available from /icecube; NCAR’s RDA is available from /ncar-rda) and the object can be referenced from within the prefix.\n\nFrom our RouteViews example above, we were interested in accessing the object named chicago/route-views.chicago/bgpdata/2025.03/RIBS/rib.20250319.0400.bz2.  Since the prefix for RouteViews is /routeviews, the entire OSDF name is:osdf://routeviews/chicago/route-views.chicago/bgpdata/2025.03/RIBS/rib.20250319.0400.bz2\n\n“Objects” vs “Files”: You may have noticed that this notebook refers to downloading/streaming “objects” instead of “files”. What’s the difference, and why does OSDF bother making this distinction?\n\nBoth objects and files are ways for computers to store data, and in practice, the earth science calculations in this cookbook use them the same way—regardless of where the data comes from.\n\nThe key difference is the way we typically think about accessing or retrieving that data: When you open files like Word documents or images on your computer, you probably click through folders or directories to find them. But when you’re working with data over the internet, that folder-based structure doesn’t always apply.\n\nIn the OSDF, an object is simply a piece of data that can be shared, like a file—but without needing to think about where it’s stored or how it’s organized on someone else’s computer. “Object” is a more flexible term that works better when data is stored in large systems across many locations.\n\nWarning\n\nImmutable Objects: The OSDF assumes that objects are immutable; once created, they aren’t permitted to be changed.  This allows OSDF to effectively make copies of the objects in the caches.\n\nThis typically works well with scientific datasets: you rarely change your data after you record it!  However, if you start using OSDF more heavily, this is an important requirement to be aware of.","type":"content","url":"/notebooks/osdf-intro#about-the-osdf","position":5},{"hierarchy":{"lvl1":"Streaming Data with the Open Science Data Federation (OSDF)","lvl2":"Finding My Objects"},"type":"lvl2","url":"/notebooks/osdf-intro#finding-my-objects","position":6},{"hierarchy":{"lvl1":"Streaming Data with the Open Science Data Federation (OSDF)","lvl2":"Finding My Objects"},"content":"How do you find the object you’re interested in?\n\nTypically, dataset providers connected to the OSDF provide a search, data catalog, or STAC catalog publishing OSDF-style URLs.  You can determine this from the provider’s website; additionally, OSDF maintains a \n\nlist of known links you can peruse.\n\nExplore this cookbook: This cookbook provides examples for how to use OSDF to access:\n\nNCAR’s Research Data Archive.\n\nAWS’s OpenData Program.\n\nThe Envistor platform at Florida International University.","type":"content","url":"/notebooks/osdf-intro#finding-my-objects","position":7},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"type":"lvl1","url":"/notebooks/cesm2-lens","position":0},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"content":"Let’s start here! If you can directly link to an image relevant to your notebook, such as \n\ncanonical logos, do so here at the top of your notebook. You can do this with MyST Markdown syntax, outlined in \n\nthis MyST guide, or you edit this cell to see a demonstration. Be sure to include alt text for any embedded images to make your content more accessible.\n\nNext, title your notebook appropriately with a top-level Markdown header, # (see the very first cell above). Do not use this level header anywhere else in the notebook. Our book build process will use this title in the navbar, table of contents, etc. Keep it short, keep it descriptive.\n\nFollow this with a --- cell to visually distinguish the transition to the prerequisites section.\n\n\n\n","type":"content","url":"/notebooks/cesm2-lens","position":1},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/cesm2-lens#overview","position":2},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Overview"},"content":"If you have an introductory paragraph, lead with it here! Keep it short and tied to your material, then be sure to continue into the required list of topics below,\n\nThis is a numbered list of the specific topics\n\nThese should map approximately to your main sections of content\n\nOr each second-level, ##, header in your notebook\n\nKeep the size and scope of your notebook in check\n\nAnd be sure to let the reader know up front the important concepts they’ll be leaving with\n\n","type":"content","url":"/notebooks/cesm2-lens#overview","position":3},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/cesm2-lens#prerequisites","position":4},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Prerequisites"},"content":"This section was inspired by \n\nthis template of the wonderful \n\nThe Turing Way Jupyter Book.\n\nFollowing your overview, tell your reader what concepts, packages, or other background information they’ll need before learning your material. Tie this explicitly with links to other pages here in Foundations or to relevant external resources. Remove this body text, then populate the Markdown table, denoted in this cell with | vertical brackets, below, and fill out the information following. In this table, lay out prerequisite concepts by explicitly linking to other Foundations material or external resources, or describe generally helpful concepts.\n\nLabel the importance of each concept explicitly as helpful/necessary.\n\nConcepts\n\nImportance\n\nNotes\n\nIntro to Cartopy\n\nNecessary\n\n\n\nUnderstanding of NetCDF\n\nHelpful\n\nFamiliarity with metadata structure\n\nProject management\n\nHelpful\n\n\n\nTime to learn: estimate in minutes. For a rough idea, use 5 mins per subsection, 10 if longer; add these up for a total. Safer to round up and overestimate.\n\nSystem requirements:\n\nPopulate with any system, version, or non-Python software requirements if necessary\n\nOtherwise use the concepts table above and the Imports section below to describe required packages as necessary\n\nIf no extra requirements, remove the System requirements point altogether\n\n\n\n","type":"content","url":"/notebooks/cesm2-lens#prerequisites","position":5},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/cesm2-lens#imports","position":6},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Imports"},"content":"Begin your body of content with another --- divider before continuing into this section, then remove this body text and populate the following code cell with all necessary Python imports up-front:\n\nimport sys\n\n","type":"content","url":"/notebooks/cesm2-lens#imports","position":7},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your first content section"},"type":"lvl2","url":"/notebooks/cesm2-lens#your-first-content-section","position":8},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your first content section"},"content":"\n\nThis is where you begin your first section of material, loosely tied to your objectives stated up front. Tie together your notebook as a narrative, with interspersed Markdown text, images, and more as necessary,\n\n# as well as any and all of your code cells\nprint(\"Hello world!\")\n\n","type":"content","url":"/notebooks/cesm2-lens#your-first-content-section","position":9},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A content subsection","lvl2":"Your first content section"},"type":"lvl3","url":"/notebooks/cesm2-lens#a-content-subsection","position":10},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A content subsection","lvl2":"Your first content section"},"content":"Divide and conquer your objectives with Markdown subsections, which will populate the helpful navbar in Jupyter Lab and here on the Jupyter Book!\n\n# some subsection code\na = [1, 2, 3, 4, 5]\n[i + 2 for i in a]\n\n","type":"content","url":"/notebooks/cesm2-lens#a-content-subsection","position":11},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Another content subsection","lvl2":"Your first content section"},"type":"lvl3","url":"/notebooks/cesm2-lens#another-content-subsection","position":12},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Another content subsection","lvl2":"Your first content section"},"content":"Keep up the good work! A note, try to avoid using code comments as narrative, and instead let them only exist as brief clarifications where necessary.\n\n","type":"content","url":"/notebooks/cesm2-lens#another-content-subsection","position":13},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your second content section"},"type":"lvl2","url":"/notebooks/cesm2-lens#your-second-content-section","position":14},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your second content section"},"content":"Here we can move on to our second objective, and we can demonstrate...\n\n","type":"content","url":"/notebooks/cesm2-lens#your-second-content-section","position":15},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl3","url":"/notebooks/cesm2-lens#a-subsection-to-the-second-section","position":16},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/cesm2-lens#a-subsection-to-the-second-section","position":17},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl4","url":"/notebooks/cesm2-lens#a-quick-demonstration","position":18},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/cesm2-lens#a-quick-demonstration","position":19},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl5","url":"/notebooks/cesm2-lens#of-further-and-further","position":20},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/cesm2-lens#of-further-and-further","position":21},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl6","url":"/notebooks/cesm2-lens#header-levels","position":22},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"\n\nas well as m = a * t / h text! Similarly, you have access to other \\LaTeX equation \n\nfunctionality via MathJax:\\begin{align}\n\\dot{x} & = \\sigma(y-x) \\\\\n\\dot{y} & = \\rho x - y - xz \\\\\n\\dot{z} & = -\\beta z + xy\n\\end{align}\n\nCheck out \n\nany number of helpful Markdown resources for further customizing your notebooks and the \n\nMyST Syntax Overview for MyST-specific formatting information. Don’t hesitate to ask questions if you have problems getting it to look just right.\n\n","type":"content","url":"/notebooks/cesm2-lens#header-levels","position":23},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Last Section"},"type":"lvl2","url":"/notebooks/cesm2-lens#last-section","position":24},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Last Section"},"content":"You can add \n\nadmonitions using MyST syntax:\n\nNote\n\nYour relevant information here!\n\nSome other admonitions you can put in (\n\nthere are 10 total):\n\nHint\n\nA helpful hint.\n\nWarning\n\nBe careful!\n\nDanger\n\nScary stuff be here.\n\nWe also suggest checking out Jupyter Book’s \n\nbrief demonstration on adding cell tags to your cells in Jupyter Notebook, Lab, or manually. Using these cell tags can allow you to \n\ncustomize how your code content is displayed and even \n\ndemonstrate errors without altogether crashing our loyal army of machines!\n\n\n\n","type":"content","url":"/notebooks/cesm2-lens#last-section","position":25},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/cesm2-lens#summary","position":26},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Summary"},"content":"Add one final --- marking the end of your body of content, and then conclude with a brief single paragraph summarizing at a high level the key pieces that were learned and how they tied to your objectives. Look to reiterate what the most important takeaways were.","type":"content","url":"/notebooks/cesm2-lens#summary","position":27},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/cesm2-lens#whats-next","position":28},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"What’s next?","lvl2":"Summary"},"content":"Let Jupyter book tie this to the next (sequential) piece of content that people could move on to down below and in the sidebar. However, if this page uniquely enables your reader to tackle other nonsequential concepts throughout this book, or even external content, link to it here!\n\n","type":"content","url":"/notebooks/cesm2-lens#whats-next","position":29},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/cesm2-lens#resources-and-references","position":30},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Resources and references"},"content":"Finally, be rigorous in your citations and references as necessary. Give credit where credit is due. Also, feel free to link to relevant external material, further reading, documentation, etc. Then you’re done! Give yourself a quick review, a high five, and send us a pull request. A few final notes:\n\nKernel > Restart Kernel and Run All Cells... to confirm that your notebook will cleanly run from start to finish\n\nKernel > Restart Kernel and Clear All Outputs... before committing your notebook, our machines will do the heavy lifting\n\nTake credit! Provide author contact information if you’d like; if so, consider adding information here at the bottom of your notebook\n\nGive credit! Attribute appropriate authorship for referenced code, information, images, etc.\n\nOnly include what you’re legally allowed: no copyright infringement or plagiarism\n\nThank you for your contribution!","type":"content","url":"/notebooks/cesm2-lens#resources-and-references","position":31},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data"},"type":"lvl1","url":"/notebooks/cmip6-gmst","position":0},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data"},"content":" Let's start here! If you can directly link to an image relevant to your notebook, such as [canonical logos](https://github.com/numpy/numpy/blob/main/doc/source/_static/numpylogo.svg), do so here at the top of your notebook. You can do this with MyST Markdown syntax, outlined in [this MyST guide](https://mystmd.org/guide/figures), or you edit this cell to see a demonstration. **Be sure to include `alt` text for any embedded images to make your content more accessible.**\n\n```{image} ../thumbnails/thumbnail.png\n:alt: Project Pythia logo\n:width: 200px\n``` \n\n\n\n","type":"content","url":"/notebooks/cmip6-gmst","position":1},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/cmip6-gmst#overview","position":2},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl2":"Overview"},"content":"If you have an introductory paragraph, lead with it here! Keep it short and tied to your material, then be sure to continue into the required list of topics below,\n\nThis is a numbered list of the specific topics\n\nThese should map approximately to your main sections of content\n\nOr each second-level, ##, header in your notebook\n\nKeep the size and scope of your notebook in check\n\nAnd be sure to let the reader know up front the important concepts they’ll be leaving with\n\n","type":"content","url":"/notebooks/cmip6-gmst#overview","position":3},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/cmip6-gmst#prerequisites","position":4},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl2":"Prerequisites"},"content":"This section was inspired by \n\nthis template of the wonderful \n\nThe Turing Way Jupyter Book.\n\nFollowing your overview, tell your reader what concepts, packages, or other background information they’ll need before learning your material. Tie this explicitly with links to other pages here in Foundations or to relevant external resources. Remove this body text, then populate the Markdown table, denoted in this cell with | vertical brackets, below, and fill out the information following. In this table, lay out prerequisite concepts by explicitly linking to other Foundations material or external resources, or describe generally helpful concepts.\n\nLabel the importance of each concept explicitly as helpful/necessary.\n\nConcepts\n\nImportance\n\nNotes\n\nIntro to Intake-ESM\n\nNecessary\n\n\n\nUnderstanding of Zarr\n\nHelpful\n\nFamiliarity with metadata structure\n\n[Seaborn]\n\nNecessary\n\n\n\n\n\n\n\n\n\nTime to learn: estimate in minutes. For a rough idea, use 5 mins per subsection, 10 if longer; add these up for a total. Safer to round up and overestimate.\n\nSystem requirements:\n\nPopulate with any system, version, or non-Python software requirements if necessary\n\nOtherwise use the concepts table above and the Imports section below to describe required packages as necessary\n\nIf no extra requirements, remove the System requirements point altogether\n\n\n\n","type":"content","url":"/notebooks/cmip6-gmst#prerequisites","position":5},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/cmip6-gmst#imports","position":6},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl2":"Imports"},"content":"\n\nfrom matplotlib import pyplot as plt\nimport xarray as xr\nimport numpy as np\nimport dask\nfrom dask.diagnostics import progress\nfrom tqdm.autonotebook import tqdm\nimport intake\nimport fsspec\nimport seaborn as sns\n# import re\nimport aiohttp\nfrom dask.distributed import LocalCluster\nfrom dask_jobqueue import PBSCluster\n#import pandas as pd\nimport pelicanfs \n\nWe will use an intake-ESM catalog hosted on NCAR’s Research Data Archive. This is nothing but the AWS cmip6 catalog modified to use OSDF\n\n# Load catalog URL\nrda_url     =  'https://data.rda.ucar.edu/'\ncat_url     = rda_url +  'd850001/catalogs/osdf/cmip6-aws/cmip6-osdf-zarr.json'\nprint(cat_url)\n\n","type":"content","url":"/notebooks/cmip6-gmst#imports","position":7},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl2":"Set up local dask cluster and load data"},"type":"lvl2","url":"/notebooks/cmip6-gmst#set-up-local-dask-cluster-and-load-data","position":8},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl2":"Set up local dask cluster and load data"},"content":"\n\nBefore we do any computation let us first set up a local cluster using dask\n\ncluster = LocalCluster()          \nclient = cluster.get_client()\ncluster.scale(2)\ncluster\n\n","type":"content","url":"/notebooks/cmip6-gmst#set-up-local-dask-cluster-and-load-data","position":9},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl3":"A content subsection","lvl2":"Set up local dask cluster and load data"},"type":"lvl3","url":"/notebooks/cmip6-gmst#a-content-subsection","position":10},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl3":"A content subsection","lvl2":"Set up local dask cluster and load data"},"content":"Divide and conquer your objectives with Markdown subsections, which will populate the helpful navbar in Jupyter Lab and here on the Jupyter Book!\n\n# some subsection code\na = [1, 2, 3, 4, 5]\n[i + 2 for i in a]\n\n","type":"content","url":"/notebooks/cmip6-gmst#a-content-subsection","position":11},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl3":"Another content subsection","lvl2":"Set up local dask cluster and load data"},"type":"lvl3","url":"/notebooks/cmip6-gmst#another-content-subsection","position":12},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl3":"Another content subsection","lvl2":"Set up local dask cluster and load data"},"content":"Keep up the good work! A note, try to avoid using code comments as narrative, and instead let them only exist as brief clarifications where necessary.\n\n","type":"content","url":"/notebooks/cmip6-gmst#another-content-subsection","position":13},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl2":"Your second content section"},"type":"lvl2","url":"/notebooks/cmip6-gmst#your-second-content-section","position":14},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl2":"Your second content section"},"content":"Here we can move on to our second objective, and we can demonstrate...\n\n!pip show intake\n\n!pip show intake-esm\n\ncol = intake.open_esm_datastore(cat_url,read_csv_kwargs={\"engine\": \"python\"})\ncol\n\n","type":"content","url":"/notebooks/cmip6-gmst#your-second-content-section","position":15},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl3","url":"/notebooks/cmip6-gmst#a-subsection-to-the-second-section","position":16},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/cmip6-gmst#a-subsection-to-the-second-section","position":17},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl4","url":"/notebooks/cmip6-gmst#a-quick-demonstration","position":18},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/cmip6-gmst#a-quick-demonstration","position":19},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl5","url":"/notebooks/cmip6-gmst#of-further-and-further","position":20},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/cmip6-gmst#of-further-and-further","position":21},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl6","url":"/notebooks/cmip6-gmst#header-levels","position":22},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"\n\nas well as m = a * t / h text! Similarly, you have access to other \\LaTeX equation \n\nfunctionality via MathJax:\\begin{align}\n\\dot{x} & = \\sigma(y-x) \\\\\n\\dot{y} & = \\rho x - y - xz \\\\\n\\dot{z} & = -\\beta z + xy\n\\end{align}\n\nCheck out \n\nany number of helpful Markdown resources for further customizing your notebooks and the \n\nMyST Syntax Overview for MyST-specific formatting information. Don’t hesitate to ask questions if you have problems getting it to look just right.\n\n","type":"content","url":"/notebooks/cmip6-gmst#header-levels","position":23},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl2":"Last Section"},"type":"lvl2","url":"/notebooks/cmip6-gmst#last-section","position":24},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl2":"Last Section"},"content":"You can add \n\nadmonitions using MyST syntax:\n\nNote\n\nYour relevant information here!\n\nSome other admonitions you can put in (\n\nthere are 10 total):\n\nHint\n\nA helpful hint.\n\nWarning\n\nBe careful!\n\nDanger\n\nScary stuff be here.\n\nWe also suggest checking out Jupyter Book’s \n\nbrief demonstration on adding cell tags to your cells in Jupyter Notebook, Lab, or manually. Using these cell tags can allow you to \n\ncustomize how your code content is displayed and even \n\ndemonstrate errors without altogether crashing our loyal army of machines!\n\n\n\n","type":"content","url":"/notebooks/cmip6-gmst#last-section","position":25},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/cmip6-gmst#summary","position":26},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl2":"Summary"},"content":"Add one final --- marking the end of your body of content, and then conclude with a brief single paragraph summarizing at a high level the key pieces that were learned and how they tied to your objectives. Look to reiterate what the most important takeaways were.","type":"content","url":"/notebooks/cmip6-gmst#summary","position":27},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/cmip6-gmst#whats-next","position":28},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl3":"What’s next?","lvl2":"Summary"},"content":"Let Jupyter book tie this to the next (sequential) piece of content that people could move on to down below and in the sidebar. However, if this page uniquely enables your reader to tackle other nonsequential concepts throughout this book, or even external content, link to it here!\n\n","type":"content","url":"/notebooks/cmip6-gmst#whats-next","position":29},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/cmip6-gmst#resources-and-references","position":30},{"hierarchy":{"lvl1":"Global Mean Surface Temperature Anomaly from CMIP6 data","lvl2":"Resources and references"},"content":"Finally, be rigorous in your citations and references as necessary. Give credit where credit is due. Also, feel free to link to relevant external material, further reading, documentation, etc. Then you’re done! Give yourself a quick review, a high five, and send us a pull request. A few final notes:\n\nKernel > Restart Kernel and Run All Cells... to confirm that your notebook will cleanly run from start to finish\n\nKernel > Restart Kernel and Clear All Outputs... before committing your notebook, our machines will do the heavy lifting\n\nTake credit! Provide author contact information if you’d like; if so, consider adding information here at the bottom of your notebook\n\nGive credit! Attribute appropriate authorship for referenced code, information, images, etc.\n\nOnly include what you’re legally allowed: no copyright infringement or plagiarism\n\nThank you for your contribution!","type":"content","url":"/notebooks/cmip6-gmst#resources-and-references","position":31},{"hierarchy":{"lvl1":""},"type":"lvl1","url":"/notebooks/conus404","position":0},{"hierarchy":{"lvl1":""},"content":"","type":"content","url":"/notebooks/conus404","position":1},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive"},"type":"lvl1","url":"/notebooks/ncar-intro","position":0},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive"},"content":"\n\n\n\n","type":"content","url":"/notebooks/ncar-intro","position":1},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/ncar-intro#overview","position":2},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl2":"Overview"},"content":"The Research Data Archive (RDA) is a large, publicly accessible collection of atmospheric, oceanic, and related geophysical data managed at the National Center for Atmposheric Research (NCAR) sponsored by the National Science Foundation (NSF)\n\nCurrently the Research Data Archive can be visited using the link \n\nhttps://​rda​.ucar​.edu","type":"content","url":"/notebooks/ncar-intro#overview","position":3},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl3":"In this tutorial you will learn:","lvl2":"Overview"},"type":"lvl3","url":"/notebooks/ncar-intro#in-this-tutorial-you-will-learn","position":4},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl3":"In this tutorial you will learn:","lvl2":"Overview"},"content":"Purpose of the RDA\n\nTypes of data\n\nFeatures and tools\n\nAccess and connection to OSDF\n\n\n\n","type":"content","url":"/notebooks/ncar-intro#in-this-tutorial-you-will-learn","position":5},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl2":"Purpose of the RDA"},"type":"lvl2","url":"/notebooks/ncar-intro#purpose-of-the-rda","position":6},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl2":"Purpose of the RDA"},"content":"The RDA provides free access to curated data for research, with an emphasis on datasets which provide high value to NCAR and member university researchers.\n\nAdditionally, the RDA provides value added services and tools to help scientists discover, access, and manipulate data.\n\nThere is also an increasing empahsis on enabling users to stream data locally or apply computations directly to data.\n\n","type":"content","url":"/notebooks/ncar-intro#purpose-of-the-rda","position":7},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl2":"Types of Data"},"type":"lvl2","url":"/notebooks/ncar-intro#types-of-data","position":8},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl2":"Types of Data"},"content":"The RDA data has a wide variety of datasets that cover many different domains of geosciences including:\n\nGlobal and regional reanalysis datasets (e.g., \n\nERA5, \n\nNCEP/NCAR, \n\nJRA-3Q)\n\nNumerical weather prediction model output (e.g. \n\nGFS)\n\nObservational data (e.g., surface, radiosonde, satellite)\n\nClimate model simulations (e.g., \n\nCESM)\n\nOceanographic datasets (e.g. \n\nICOADS)","type":"content","url":"/notebooks/ncar-intro#types-of-data","position":9},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl3":"File Formats","lvl2":"Types of Data"},"type":"lvl3","url":"/notebooks/ncar-intro#file-formats","position":10},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl3":"File Formats","lvl2":"Types of Data"},"content":"NetCDF4\n\nGrib\n\nProprietary binary\n\nBUFR\n\nZarr\n\nKerchunk\n\n","type":"content","url":"/notebooks/ncar-intro#file-formats","position":11},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl2":"Features and Tools"},"type":"lvl2","url":"/notebooks/ncar-intro#features-and-tools","position":12},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl2":"Features and Tools"},"content":"\n\nSearch and filtering tools for finding datasets\n\nData subsetting and format conversion\n\nDocumentation and metadata for reproducibility\n\nAPIs and scripts for automated access\n\n","type":"content","url":"/notebooks/ncar-intro#features-and-tools","position":13},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl2":"Access and OSDF"},"type":"lvl2","url":"/notebooks/ncar-intro#access-and-osdf","position":14},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl2":"Access and OSDF"},"content":"All datasets are open and free to download, however registration (via ORCID) is required for subset requests\n\nIf you made it this far, you might wonder how the RDA has to do with the Open Science Data Federation (OSDF)?\n\nA:\nThe RDA is a member of the OSDF and it’s data holdings are served via an origin.\nThe implications are that subsequent requests of the same data will result in lower latency as data will be stored at a geographically close cache.\n\n\n\n","type":"content","url":"/notebooks/ncar-intro#access-and-osdf","position":15},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/ncar-intro#summary","position":16},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl2":"Summary"},"content":"In essence, the NCAR RDA is a vital resource for the climate and weather research community, providing long-term, reliable access to high-quality Earth system data.","type":"content","url":"/notebooks/ncar-intro#summary","position":17},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/ncar-intro#whats-next","position":18},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl3":"What’s next?","lvl2":"Summary"},"content":"RDA is currently undergoing a rebranding effort and will soon be renamed GDEX, which stands for Geoscience Data Exchange. Essentially, all references to RDA can be replaced with GDEX as of Sep 9, 2025.\n\n","type":"content","url":"/notebooks/ncar-intro#whats-next","position":19},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/ncar-intro#resources-and-references","position":20},{"hierarchy":{"lvl1":"Introduction to the Research Data Archive","lvl2":"Resources and references"},"content":"","type":"content","url":"/notebooks/ncar-intro#resources-and-references","position":21},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters"},"type":"lvl1","url":"/notebooks/envistor-foundations","position":0},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters"},"content":"This notebook introduces a user-facing science workflow that explores salinity patterns in South Florida using curated buoy data published through the EnviStor smart data pipeline and made accessible via PelicanFS as part of the Open Science Data Federation (OSDF).\n\nEnviStor is an AI-assisted, modular data pipeline developed at Florida International University (FIU) to process and publish environmental datasets. It automates tasks like file type detection, metadata generation, geospatial transformations, and dataset publication. For this use case, EnviStor ingested buoy data, processed and cleaned it, and published it through the OSDF federation, making it available to science users via PelicanFS.\n\n\n\n","type":"content","url":"/notebooks/envistor-foundations","position":1},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/envistor-foundations#overview","position":2},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl2":"Overview"},"content":"This notebook introduces a real-world scientific workflow built around the question: “What are the salinity patterns in South Florida?” Using curated data from FIU’s buoy network—processed by the EnviStor smart pipeline and accessed through OSDF using PelicanFS, we explore how environmental datasets can be made reproducible, discoverable, and usable by domain scientists.\n\nBelow is a breakdown of what this notebook covers:\n\n1. What is Salinity?\nA brief introduction to salinity, its units, and its role in coastal science.\n\n2. Why South Florida?\nContext around why this region is important for salinity monitoring, including environmental and societal implications.\n\n3. About the Dataset\nDescription of the FIU CREST buoy network, the variables collected, and how the data is prepared through EnviStor.\n\n4. Data Access with PelicanFS\nExplanation of how the dataset is accessed directly from OSDF using PelicanFS, and how that supports open science.\n\n5. Research Question\nA clear framing of the central question that will be explored in the analysis notebook.\n\n6. What’s Next?\nA preview of what readers will do in the second notebook: loading, analyzing, and visualizing the data.\n\nBy the end of this notebook, the reader should understand the scientific motivation, the data context, and how curated environmental data made available via OSDF can be leveraged in reproducible Jupyter-based workflows.\n\n","type":"content","url":"/notebooks/envistor-foundations#overview","position":3},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/envistor-foundations#prerequisites","position":4},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl2":"Prerequisites"},"content":"To fully understand the context and content of this notebook, readers should be familiar with a few foundational concepts and tools. While this notebook itself is explanatory and doesn’t run any code, it introduces ideas and data structures that are implemented in the accompanying technical notebook.\n\nBelow is a table of key concepts and how important they are for this material:\n\nConcepts\n\nImportance\n\nNotes\n\nWhat is Salinity?\n\nNecessary\n\nCore environmental concept used in the notebook\n\nIntro to Buoy-based monitoring\n\nHelpful\n\nUnderstanding how buoy data is collected\n\nPelicanFS Overview\n\nNecessary\n\nExplains how the curated data is accessed from OSDF\n\nWhat is OSDF\n\nHelpful\n\nHigh-level context for how EnviStor data is shared\n\nTime to learn: 20-30 minutes. (~5–10 minutes per external concept; extra time optional for those new to Pelican/OSDF)\n\n\n\n","type":"content","url":"/notebooks/envistor-foundations#prerequisites","position":5},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl2":"What is Salinity?"},"type":"lvl2","url":"/notebooks/envistor-foundations#what-is-salinity","position":6},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl2":"What is Salinity?"},"content":"Salinity measures how much salt is dissolved in water, typically in Practical Salinity Units (PSU).\n\nSalinity influences ocean circulation, marine life, and freshwater availability. In coastal regions like South Florida, it’s a key indicator of environmental change, particularly for detecting saltwater intrusion into freshwater systems.\n\n","type":"content","url":"/notebooks/envistor-foundations#what-is-salinity","position":7},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl2":"Why South Florida?"},"type":"lvl2","url":"/notebooks/envistor-foundations#why-south-florida","position":8},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl2":"Why South Florida?"},"content":"South Florida is particularly sensitive to salinity changes due to its mix of freshwater inflows, tidal dynamics, sea level rise, and storm surge events. Monitoring salinity helps scientists detect:\n\nSaltwater intrusion into aquifers\n\nSeasonal or storm-related shifts in water quality\n\nLong-term climate-driven changes\n\n","type":"content","url":"/notebooks/envistor-foundations#why-south-florida","position":9},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl2":"About the Dataset"},"type":"lvl2","url":"/notebooks/envistor-foundations#about-the-dataset","position":10},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl2":"About the Dataset"},"content":"This dataset comes from FIU’s CREST buoy network, which continuously measures water quality parameters including salinity, temperature, turbidity, and more.\n\nFor this analysis, we selected three stations:\n\nBuoy 2: NW Biscayne Bay\n\nBuoy 3: Haulover Inlet\n\nBuoy 3-2: Little River\n\nThese datasets were processed through the EnviStor smart pipeline, which cleaned, standardized, and published them into the Open Science Data Federation (OSDF). The data is now directly accessible using PelicanFS, a high-performance data access layer.\n\n","type":"content","url":"/notebooks/envistor-foundations#about-the-dataset","position":11},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl2":"Data Access with PelicanFS"},"type":"lvl2","url":"/notebooks/envistor-foundations#data-access-with-pelicanfs","position":12},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl2":"Data Access with PelicanFS"},"content":"The curated data is available in the /envistor namespace on OSDF. We will access it directly in the next notebook using PelicanFS, a high-performance file system interface developed by the OSG and Pathfinders community.\n\nNo pre-downloaded files are needed — all data will be loaded live from OSDF via PelicanFS.\n\nNote\n\nIf you’re running this notebook as part of the Pythia Cook-off, PelicanFS is already set up in the environment — no extra steps are needed.\n\nHowever, if you’re adapting this workflow for use outside the Cook-off platform, you’ll need to install and mount PelicanFS on your system to access data from OSDF. For instructions, see the \n\nPelican documentation.\n\n","type":"content","url":"/notebooks/envistor-foundations#data-access-with-pelicanfs","position":13},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl2":"Research Question"},"type":"lvl2","url":"/notebooks/envistor-foundations#research-question","position":14},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl2":"Research Question"},"content":"We aim to explore:“How does water salinity vary across time and space in South Florida coastal waters?”\n\nThis question is central to understanding environmental patterns related to:\n\nSeasonality (e.g., wet vs. dry season)\n\nFreshwater discharge (e.g., from canals or rivers)\n\nSaltwater intrusion (e.g., due to sea level rise or storm surge)\n\nTo answer it, we will compare salinity data collected from three distinct coastal monitoring stations (NW Biscayne Bay, Haulover Inlet, and Little River) over a multi-month period. These stations span both urban and natural areas, helping us examine spatial variation.\n\nBy plotting and analyzing this data over time, we can begin to identify how salinity responds to both natural processes and human-driven impacts — providing insights useful for coastal management and long-term monitoring.\n\n\n\n","type":"content","url":"/notebooks/envistor-foundations#research-question","position":15},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/envistor-foundations#summary","position":16},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl2":"Summary"},"content":"In this notebook, we explored the motivation, context, and scientific importance of analyzing salinity patterns in South Florida. We introduced the curated buoy datasets processed through the EnviStor smart data pipeline and made accessible via PelicanFS, part of the Open Science Data Federation. The reader now understands why salinity matters, how the data was collected and prepared, and what question the upcoming technical notebook will answer. This context sets the stage for a reproducible, user-facing environmental analysis powered by FAIR data infrastructure.","type":"content","url":"/notebooks/envistor-foundations#summary","position":17},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl3":"What’s Next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/envistor-foundations#whats-next","position":18},{"hierarchy":{"lvl1":"Exploring Salinity Patterns in South Florida Coastal Waters","lvl3":"What’s Next?","lvl2":"Summary"},"content":"In the next notebook, we will:\n\nLoad salinity datasets for three buoy stations (NW Biscayne Bay, Haulover Inlet, and Little River) directly from OSDF via PelicanFS.\n\nCombine and clean the data: We’ll merge the datasets into a single time series, convert timestamps, label each station, and handle any missing or invalid salinity readings.\n\nResample to daily averages to reduce noise and highlight broader trends.\n\nVisualize the results using line plots to show salinity over time for each location, making it easy to compare patterns across stations.\n\nAnalyze temporal and spatial patterns, such as seasonal variations, sudden shifts, or location-specific behaviors that may suggest environmental changes like saltwater intrusion or storm impact.\n\nThis notebook will give users a complete, reproducible workflow that demonstrates how curated environmental data can be analyzed using standard Python tools — all made possible by the EnviStor pipeline and OSDF infrastructure.","type":"content","url":"/notebooks/envistor-foundations#whats-next","position":19},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"type":"lvl1","url":"/notebooks/foundations","position":0},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"content":"Let’s start here! If you can directly link to an image relevant to your notebook, such as \n\ncanonical logos, do so here at the top of your notebook. You can do this with MyST Markdown syntax, outlined in \n\nthis MyST guide, or you edit this cell to see a demonstration. Be sure to include alt text for any embedded images to make your content more accessible.\n\nNext, title your notebook appropriately with a top-level Markdown header, # (see the very first cell above). Do not use this level header anywhere else in the notebook. Our book build process will use this title in the navbar, table of contents, etc. Keep it short, keep it descriptive.\n\nFollow this with a --- cell to visually distinguish the transition to the prerequisites section.\n\n\n\n","type":"content","url":"/notebooks/foundations","position":1},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/foundations#overview","position":2},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Overview"},"content":"If you have an introductory paragraph, lead with it here! Keep it short and tied to your material, then be sure to continue into the required list of topics below,\n\nThis is a numbered list of the specific topics\n\nThese should map approximately to your main sections of content\n\nOr each second-level, ##, header in your notebook\n\nKeep the size and scope of your notebook in check\n\nAnd be sure to let the reader know up front the important concepts they’ll be leaving with\n\n","type":"content","url":"/notebooks/foundations#overview","position":3},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/foundations#prerequisites","position":4},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Prerequisites"},"content":"This section was inspired by \n\nthis template of the wonderful \n\nThe Turing Way Jupyter Book.\n\nFollowing your overview, tell your reader what concepts, packages, or other background information they’ll need before learning your material. Tie this explicitly with links to other pages here in Foundations or to relevant external resources. Remove this body text, then populate the Markdown table, denoted in this cell with | vertical brackets, below, and fill out the information following. In this table, lay out prerequisite concepts by explicitly linking to other Foundations material or external resources, or describe generally helpful concepts.\n\nLabel the importance of each concept explicitly as helpful/necessary.\n\nConcepts\n\nImportance\n\nNotes\n\nIntro to Cartopy\n\nNecessary\n\n\n\nUnderstanding of NetCDF\n\nHelpful\n\nFamiliarity with metadata structure\n\nProject management\n\nHelpful\n\n\n\nTime to learn: estimate in minutes. For a rough idea, use 5 mins per subsection, 10 if longer; add these up for a total. Safer to round up and overestimate.\n\nSystem requirements:\n\nPopulate with any system, version, or non-Python software requirements if necessary\n\nOtherwise use the concepts table above and the Imports section below to describe required packages as necessary\n\nIf no extra requirements, remove the System requirements point altogether\n\n\n\n","type":"content","url":"/notebooks/foundations#prerequisites","position":5},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/foundations#imports","position":6},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Imports"},"content":"Begin your body of content with another --- divider before continuing into this section, then remove this body text and populate the following code cell with all necessary Python imports up-front:\n\nimport sys\n\n","type":"content","url":"/notebooks/foundations#imports","position":7},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your first content section"},"type":"lvl2","url":"/notebooks/foundations#your-first-content-section","position":8},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your first content section"},"content":"\n\nThis is where you begin your first section of material, loosely tied to your objectives stated up front. Tie together your notebook as a narrative, with interspersed Markdown text, images, and more as necessary,\n\n# as well as any and all of your code cells\nprint(\"Hello world!\")\n\n","type":"content","url":"/notebooks/foundations#your-first-content-section","position":9},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A content subsection","lvl2":"Your first content section"},"type":"lvl3","url":"/notebooks/foundations#a-content-subsection","position":10},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A content subsection","lvl2":"Your first content section"},"content":"Divide and conquer your objectives with Markdown subsections, which will populate the helpful navbar in Jupyter Lab and here on the Jupyter Book!\n\n# some subsection code\na = [1, 2, 3, 4, 5]\n[i + 2 for i in a]\n\n","type":"content","url":"/notebooks/foundations#a-content-subsection","position":11},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Another content subsection","lvl2":"Your first content section"},"type":"lvl3","url":"/notebooks/foundations#another-content-subsection","position":12},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Another content subsection","lvl2":"Your first content section"},"content":"Keep up the good work! A note, try to avoid using code comments as narrative, and instead let them only exist as brief clarifications where necessary.\n\n","type":"content","url":"/notebooks/foundations#another-content-subsection","position":13},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your second content section"},"type":"lvl2","url":"/notebooks/foundations#your-second-content-section","position":14},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your second content section"},"content":"Here we can move on to our second objective, and we can demonstrate...\n\n","type":"content","url":"/notebooks/foundations#your-second-content-section","position":15},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl3","url":"/notebooks/foundations#a-subsection-to-the-second-section","position":16},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/foundations#a-subsection-to-the-second-section","position":17},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl4","url":"/notebooks/foundations#a-quick-demonstration","position":18},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/foundations#a-quick-demonstration","position":19},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl5","url":"/notebooks/foundations#of-further-and-further","position":20},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/foundations#of-further-and-further","position":21},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl6","url":"/notebooks/foundations#header-levels","position":22},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"\n\nas well as m = a * t / h text! Similarly, you have access to other \\LaTeX equation \n\nfunctionality via MathJax:\\begin{align}\n\\dot{x} & = \\sigma(y-x) \\\\\n\\dot{y} & = \\rho x - y - xz \\\\\n\\dot{z} & = -\\beta z + xy\n\\end{align}\n\nCheck out \n\nany number of helpful Markdown resources for further customizing your notebooks and the \n\nMyST Syntax Overview for MyST-specific formatting information. Don’t hesitate to ask questions if you have problems getting it to look just right.\n\n","type":"content","url":"/notebooks/foundations#header-levels","position":23},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Last Section"},"type":"lvl2","url":"/notebooks/foundations#last-section","position":24},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Last Section"},"content":"You can add \n\nadmonitions using MyST syntax:\n\nNote\n\nYour relevant information here!\n\nSome other admonitions you can put in (\n\nthere are 10 total):\n\nHint\n\nA helpful hint.\n\nWarning\n\nBe careful!\n\nDanger\n\nScary stuff be here.\n\nWe also suggest checking out Jupyter Book’s \n\nbrief demonstration on adding cell tags to your cells in Jupyter Notebook, Lab, or manually. Using these cell tags can allow you to \n\ncustomize how your code content is displayed and even \n\ndemonstrate errors without altogether crashing our loyal army of machines!\n\n\n\n","type":"content","url":"/notebooks/foundations#last-section","position":25},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/foundations#summary","position":26},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Summary"},"content":"Add one final --- marking the end of your body of content, and then conclude with a brief single paragraph summarizing at a high level the key pieces that were learned and how they tied to your objectives. Look to reiterate what the most important takeaways were.","type":"content","url":"/notebooks/foundations#summary","position":27},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/foundations#whats-next","position":28},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"What’s next?","lvl2":"Summary"},"content":"Let Jupyter book tie this to the next (sequential) piece of content that people could move on to down below and in the sidebar. However, if this page uniquely enables your reader to tackle other nonsequential concepts throughout this book, or even external content, link to it here!\n\n","type":"content","url":"/notebooks/foundations#whats-next","position":29},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/foundations#resources-and-references","position":30},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Resources and references"},"content":"Finally, be rigorous in your citations and references as necessary. Give credit where credit is due. Also, feel free to link to relevant external material, further reading, documentation, etc. Then you’re done! Give yourself a quick review, a high five, and send us a pull request. A few final notes:\n\nKernel > Restart Kernel and Run All Cells... to confirm that your notebook will cleanly run from start to finish\n\nKernel > Restart Kernel and Clear All Outputs... before committing your notebook, our machines will do the heavy lifting\n\nTake credit! Provide author contact information if you’d like; if so, consider adding information here at the bottom of your notebook\n\nGive credit! Attribute appropriate authorship for referenced code, information, images, etc.\n\nOnly include what you’re legally allowed: no copyright infringement or plagiarism\n\nThank you for your contribution!","type":"content","url":"/notebooks/foundations#resources-and-references","position":31},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"type":"lvl1","url":"/notebooks/init-datasets","position":0},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"content":"Let’s start here! If you can directly link to an image relevant to your notebook, such as \n\ncanonical logos, do so here at the top of your notebook. You can do this with MyST Markdown syntax, outlined in \n\nthis MyST guide, or you edit this cell to see a demonstration. Be sure to include alt text for any embedded images to make your content more accessible.\n\nNext, title your notebook appropriately with a top-level Markdown header, # (see the very first cell above). Do not use this level header anywhere else in the notebook. Our book build process will use this title in the navbar, table of contents, etc. Keep it short, keep it descriptive.\n\nFollow this with a --- cell to visually distinguish the transition to the prerequisites section.\n\n\n\n","type":"content","url":"/notebooks/init-datasets","position":1},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/init-datasets#overview","position":2},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Overview"},"content":"If you have an introductory paragraph, lead with it here! Keep it short and tied to your material, then be sure to continue into the required list of topics below,\n\nThis is a numbered list of the specific topics\n\nThese should map approximately to your main sections of content\n\nOr each second-level, ##, header in your notebook\n\nKeep the size and scope of your notebook in check\n\nAnd be sure to let the reader know up front the important concepts they’ll be leaving with\n\n","type":"content","url":"/notebooks/init-datasets#overview","position":3},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/init-datasets#prerequisites","position":4},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Prerequisites"},"content":"This section was inspired by \n\nthis template of the wonderful \n\nThe Turing Way Jupyter Book.\n\nFollowing your overview, tell your reader what concepts, packages, or other background information they’ll need before learning your material. Tie this explicitly with links to other pages here in Foundations or to relevant external resources. Remove this body text, then populate the Markdown table, denoted in this cell with | vertical brackets, below, and fill out the information following. In this table, lay out prerequisite concepts by explicitly linking to other Foundations material or external resources, or describe generally helpful concepts.\n\nLabel the importance of each concept explicitly as helpful/necessary.\n\nConcepts\n\nImportance\n\nNotes\n\nIntro to Cartopy\n\nNecessary\n\n\n\nUnderstanding of NetCDF\n\nHelpful\n\nFamiliarity with metadata structure\n\nProject management\n\nHelpful\n\n\n\nTime to learn: estimate in minutes. For a rough idea, use 5 mins per subsection, 10 if longer; add these up for a total. Safer to round up and overestimate.\n\nSystem requirements:\n\nPopulate with any system, version, or non-Python software requirements if necessary\n\nOtherwise use the concepts table above and the Imports section below to describe required packages as necessary\n\nIf no extra requirements, remove the System requirements point altogether\n\n\n\n","type":"content","url":"/notebooks/init-datasets#prerequisites","position":5},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/init-datasets#imports","position":6},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Imports"},"content":"Begin your body of content with another --- divider before continuing into this section, then remove this body text and populate the following code cell with all necessary Python imports up-front:\n\nimport xarray as xr\nimport s3fs\nimport pelicanfs as pefs\n\n","type":"content","url":"/notebooks/init-datasets#imports","position":7},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Initializing the datasets"},"type":"lvl2","url":"/notebooks/init-datasets#initializing-the-datasets","position":8},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Initializing the datasets"},"content":"\n\nThis is where you begin your first section of material, loosely tied to your objectives stated up front. Tie together your notebook as a narrative, with interspersed Markdown text, images, and more as necessary,\n\ndef init_datasets():\n    bucket_name = 'noaa-wcsd-zarr-pds'\n    ship_name = \"Henry_B._Bigelow\"\n    cruise_name = \"HB1906\"\n    sensor_name = \"EK60\"\n\n    s3_file_system = s3fs.S3FileSystem(anon=True)\n    zarr_store = f'{cruise_name}.zarr'\n    s3_zarr_store_path = f\"{bucket_name}/level_2/{ship_name}/{cruise_name}/{sensor_name}/{zarr_store}\"\n    store = s3fs.S3Map(root=s3_zarr_store_path, s3=s3_file_system, check=False)\n    cruise = xr.open_zarr(store=store, consolidated=None)\n    start_time = \"2019-10-16T15:00:00\"\n    end_time = \"2019-10-16T23:30:00\"\n    timeslice = slice(start_time, end_time)\n    #\n    cruise = cruise.sel(time=timeslice, drop=False)\n    cruise = cruise.sel(frequency=38000, method='nearest')\n    print(cruise)\n\n    # location of one specific buoy located on Georges Bank\n    target_lon = 360 - 66.546\n    target_lat = 41.088\n    print(f\"Target coordinates: Longitude: {target_lon}, Latitude: {target_lat}\")\n\n    bouy_data_day_before = xr.open_dataset(\n        'https://data.rda.ucar.edu/d277007/avhrr_v2.1/2019/oisst-avhrr-v02r01.20191012.nc#mode=bytes', engine='netcdf4')\n    buoy_data_actual_day = xr.open_dataset(\n        'https://data.rda.ucar.edu/d277007/avhrr_v2.1/2019/oisst-avhrr-v02r01.20191013.nc#mode=bytes',\n        engine='netcdf4')\n    buoy_data_day_after = xr.open_dataset(\n        'https://data.rda.ucar.edu/d277007/avhrr_v2.1/2019/oisst-avhrr-v02r01.20191014.nc#mode=bytes',\n        engine='netcdf4')\n    sst_day_before = bouy_data_day_before['sst'].sel(lon=target_lon, lat=target_lat, method='nearest').values[0][0]\n    sst_actual_day = buoy_data_actual_day['sst'].sel(lon=target_lon, lat=target_lat, method='nearest').values[0][0]\n    sst_day_after = buoy_data_day_after['sst'].sel(lon=target_lon, lat=target_lat, method='nearest').values[0][0]\n\n    return sst_day_before, sst_actual_day, sst_day_after, cruise\n\n","type":"content","url":"/notebooks/init-datasets#initializing-the-datasets","position":9},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Data Preprocessing","lvl2":"Initializing the datasets"},"type":"lvl3","url":"/notebooks/init-datasets#data-preprocessing","position":10},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Data Preprocessing","lvl2":"Initializing the datasets"},"content":"Keep up the good work! A note, try to avoid using code comments as narrative, and instead let them only exist as brief clarifications where necessary.\n\n# baseline_timestamps = cruise.time.values\n# sst = np.full(shape=baseline_timestamps.shape, fill_value=np.nan)\n# df = pd.DataFrame(sst, columns=['sst'], index=baseline_timestamps)\n# df.loc[df.index[0],'sst'] = sst_day_before\n# df.loc[df.index[-1],'sst'] = sst_day_after\n# # print(int((len(df.index)/2)))\n# df.loc[df.index[int((len(df.index)/2))],'sst'] = sst_actual_day\n# df = df.interpolate(method='time')\n# print(df)\n\n","type":"content","url":"/notebooks/init-datasets#data-preprocessing","position":11},{"hierarchy":{"lvl1":"Use the GeoJSON file to get the Area of Interest and query the STAC catalog for items"},"type":"lvl1","url":"/notebooks/pycogss-spectral-change","position":0},{"hierarchy":{"lvl1":"Use the GeoJSON file to get the Area of Interest and query the STAC catalog for items"},"content":"# Imports\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport xarray as xr\nimport re\nfrom pelicanfs.core import PelicanFileSystem, PelicanMap,OSDFFileSystem \nimport geopandas as gpd\nfrom pystac_client import Client\nfrom rasterio.mask import mask\nimport rasterio\nfrom shapely.geometry import box\nfrom urllib.parse import urlparse\n\n","type":"content","url":"/notebooks/pycogss-spectral-change","position":1},{"hierarchy":{"lvl1":"Use the GeoJSON file to get the Area of Interest and query the STAC catalog for items"},"type":"lvl1","url":"/notebooks/pycogss-spectral-change#use-the-geojson-file-to-get-the-area-of-interest-and-query-the-stac-catalog-for-items","position":2},{"hierarchy":{"lvl1":"Use the GeoJSON file to get the Area of Interest and query the STAC catalog for items"},"content":"\n\n# Load the GeoJSON file\ngeojson_path = '3100180240.geojson' \ngdf = gpd.read_file(geojson_path)\n\n# Display the loaded GeoDataFrame\nprint(gdf)\n\n# Extract AOI geometry\naoi_geometry = gdf.geometry.iloc[0]\naoi_bounds   = aoi_geometry.bounds  # (minx, miny, maxx, maxy)\n\n# Get AOI centroid for visualization\ncentroid  = aoi_geometry.centroid\nlong, lat = centroid.x, centroid.y\n\n# Print the bounding box to verify\nprint(\"Bounding Box:\", aoi_bounds)\n\n# Connect to the Earth Search STAC API (Sentinel-2 Level-2A COGs are available here)\ncatalog_url = \"https://earth-search.aws.element84.com/v1\"\ncatalog     = Client.open(catalog_url)\n\n# Define the date range as strings\nstart_date      = \"2019-01\"\nend_date        = \"2023-02\"\n\n# Define cloud cover threshold\ncloud_cover_max = 0.05  # 5% cloud cover threshold\n#cloud_cover_max = 0.20  # 20% cloud cover threshold\n\n# Perform the search\nsearch = catalog.search(\n                 collections=[\"sentinel-2-l2a\"],\n                 bbox=aoi_bounds,\n                 datetime=f\"{start_date}/{end_date}\",\n                 #datetime=\"2022-06-01/2022-09-30\",\n                 query={\"eo:cloud_cover\": {\"lt\": cloud_cover_max * 100}}\n                )\n\n# Get all matching items\nitems = list(search.items())\nprint(f\"Found {len(items)} matching items.\")\n\n# Confirm that the matching items are hosted in a aws-us-region by printing out the href links for the first n items\nn=1\n\nfor i, item in enumerate(items[:n]):\n    print(f\"\\nItem {i+1}: {item.id}\")\n    for asset_key, asset in item.assets.items():\n        print(f\"  {asset_key}: {asset.href}\")\n\nfrom shapely.geometry import mapping\n\n# Reproject AOI to match raster CRS\nfrom pyproj import CRS\nfrom geopandas import GeoSeries\n\ndef returnOSDFPath(url):\n    \"\"\"\n    Converts a URL to an OSDF path.\n\n    Parameters:\n    - url: URL to convert.\n\n    Returns:\n    - OSDF path.\n    \"\"\"\n    # Parse the URL\n    parsed_url = urlparse(url)\n    \n    # Construct the OSDF path\n    osdf_path = f\"/aws-opendata/us-west-2/sentinel-cogs{parsed_url.path}\"\n    \n    return osdf_path\n\n\n","type":"content","url":"/notebooks/pycogss-spectral-change#use-the-geojson-file-to-get-the-area-of-interest-and-query-the-stac-catalog-for-items","position":3},{"hierarchy":{"lvl1":"Apply various masks and calculate NDVI"},"type":"lvl1","url":"/notebooks/pycogss-spectral-change#apply-various-masks-and-calculate-ndvi","position":4},{"hierarchy":{"lvl1":"Apply various masks and calculate NDVI"},"content":"\n\ndef clp(image_src, aoi_geometry):\n    \"\"\"\n    Clip a raster image to the Area of Interest (AOI).\n\n    Parameters:\n    - image_src: Open rasterio dataset.\n    - aoi_geometry: AOI geometry as a GeoJSON-like object.\n\n    Returns:\n    - Clipped image array and updated metadata.\n    \"\"\"\n    # out_image, out_transform = mask(image_src, [aoi_geometry], crop=True)\n    out_image, out_transform = mask(image_src, aoi_geometry, crop=True)\n    out_meta = image_src.meta.copy()\n    out_meta.update({\n        \"driver\": \"GTiff\",\n        \"height\": out_image.shape[1],\n        \"width\": out_image.shape[2],\n        \"transform\": out_transform\n    })\n    return out_image, out_meta\n\ndef maskWater(image, water_mask):\n    \"\"\"\n    Masks out water pixels using the MODIS water mask.\n\n    Parameters:\n    - image: Raster image to mask.\n    - water_mask: Water mask raster.\n\n    Returns:\n    - Water-masked image.\n    \"\"\"\n    water = water_mask.read(1)  # Read the water mask\n    mask = water < 1  # Mask water pixels (water < 1)\n    image_masked = np.where(mask, image, np.nan)\n    return image_masked\n\ndef maskS2snow(image, snow_prob):\n    \"\"\"\n    Masks snow pixels using the MSK_SNWPRB (Snow Probability Mask).\n\n    Parameters:\n    - image: Raster image to mask.\n    - snow_prob: Snow probability raster.\n\n    Returns:\n    - Snow-masked image.\n    \"\"\"\n    snow = snow_prob.read(1)  # Read the snow probability mask\n    mask = snow < 0.009  # Mask snow pixels (snow probability < 0.9%)\n    image_masked = np.where(mask, image, np.nan)\n    return image_masked\n\ndef maskWhite(image, b2, b3, b4):\n    \"\"\"\n    Masks white pixels by converting RGB to grayscale and applying a threshold.\n\n    Parameters:\n    - image: Raster image to mask.\n    - b2, b3, b4: Blue, Green, and Red bands respectively.\n\n    Returns:\n    - Grayscale-masked image.\n    \"\"\"\n    # Convert RGB to grayscale\n    grayscale = (0.3 * b4.read(1) + 0.59 * b3.read(1) + 0.11 * b2.read(1)) * 1e4\n    mask = grayscale <= 2000  # Mask white pixels (grayscale > 2000)\n    image_masked = np.where(mask, image, np.nan)\n    return image_masked\n\n%%time\n# # Using pelicanfs\n# Loop through each item in the STAC query\nfor idx, item in enumerate(items, start=1):\n    print(f\"Processing dataset #{idx}\")\n    if idx == 6: # Otherwise \n        break\n\n    # Check required assets\n    required_assets = [\"red\", \"green\", \"blue\", \"scl\"]\n    if not all(asset in item.assets for asset in required_assets):\n        print(f\"Skipping dataset #{idx}: Missing required assets.\")\n        continue\n\n    # Get asset URLs\n    red_url = item.assets[\"red\"].href\n    green_url = item.assets[\"green\"].href\n    blue_url = item.assets[\"blue\"].href\n    scl_url = item.assets[\"scl\"].href\n\n    pel_red_url   = returnOSDFPath(red_url)\n    pel_green_url = returnOSDFPath(green_url)\n    pel_blue_url  = returnOSDFPath(blue_url)\n    pel_scl_url   = returnOSDFPath(scl_url)\n\n    pelfs = PelicanFileSystem(\"pelican://osg-htc.org\")\n\n    # Reproject AOI to match raster CRS\n    with rasterio.open(pel_red_url,opener=pelfs) as src:\n        raster_crs = CRS(src.crs)\n    aoi_geometry_reprojected = GeoSeries(aoi_geometry).set_crs(gdf.crs).to_crs(raster_crs)\n\n    # Reproject AOI to match raster CRS\n    with rasterio.open(pel_red_url, opener=pelfs) as red_src, \\\n         rasterio.open(pel_green_url, opener=pelfs) as green_src, \\\n         rasterio.open(pel_blue_url, opener=pelfs) as blue_src, \\\n         rasterio.open(pel_scl_url, opener=pelfs) as scl_src:\n\n        aoi_geometry_reprojected = GeoSeries(aoi_geometry).set_crs(gdf.crs).to_crs(raster_crs)\n        raster_bounds = box(*red_src.bounds)\n\n        if not aoi_geometry_reprojected[0].intersects(raster_bounds):\n            print(f\"Warning: AOI does not intersect the bounds of {red_url}. Skipping.\")\n            continue\n\n        # Clip all RGB and SCL bands to AOI\n        red_clipped, red_meta = clp(red_src, aoi_geometry_reprojected)\n        green_clipped, _      = clp(green_src, aoi_geometry_reprojected)\n        blue_clipped, _       = clp(blue_src, aoi_geometry_reprojected)\n        scl_clipped, _        = clp(scl_src, aoi_geometry_reprojected)\n\n        print(f\"Dataset #{idx} processed. Ready for visualization or further analysis.\")\n\nfrom sklearn.preprocessing import MinMaxScaler\n# Function to scale image bands properly\ndef scale_band(band):\n    scaler = MinMaxScaler(feature_range=(0, 1))\n    return scaler.fit_transform(band)  # Normalize between 0-1\n\n# Assuming red_clipped, green_clipped, and blue_clipped are 2D NumPy arrays\nrgb = np.dstack((scale_band(red_clipped.squeeze()),\n    scale_band(green_clipped.squeeze()),\n    scale_band(blue_clipped.squeeze()),\n))\n\n# Plot\nplt.figure(figsize=(10, 8))\nplt.imshow(rgb)\nplt.axis(\"off\")\nplt.show()","type":"content","url":"/notebooks/pycogss-spectral-change#apply-various-masks-and-calculate-ndvi","position":5},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook"},"type":"lvl1","url":"/notebooks/atmosphere-llc2160-visualization","position":0},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook"},"content":"\n\nThe DYnamics of the Atmospheric general circulation Modeled On Non-hydrostatic Domains (DYAMOND) data provides high resolution ocean circulation models, offering unprecedented detail. This dataset comprises a C1440 configuration of the Goddard Earth Observing System (GEOS) atmospheric model, with 7-km horizontal grid spacing and 72 vertical layers, coupled to a LLC2160 configuration of the Massachusetts Institute of Technology general circulation model (MITgcm) with 2–4-km grid spacing and 90 vertical levels. The C1440-LLC2160 simulation has been integrated for 14 months, starting from prescribed initial conditions on January 20, 2020.\n\nThis notebook is the second part of the DYAMOND LLC2160 Ocean Dataset Cookbook.\n\n","type":"content","url":"/notebooks/atmosphere-llc2160-visualization","position":1},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook","lvl3":"Overview"},"type":"lvl3","url":"/notebooks/atmosphere-llc2160-visualization#overview","position":2},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook","lvl3":"Overview"},"content":"This notebook demonstrates how to access and visualize high-resolution atmospheric data from the DYAMOND dataset using OpenVisus. The data is hosted in OSDF and served using Pelican Platform and OpenVisus. You’ll learn how to read metadata from the cloud, interactively select variables, and explore regional and depth-based slices of the data.\n\nRead the metadata file from cloud\n\nData Subset\n\nVisualize the data\n\nExplore multi-resolution data for a specific region and depth\n\nBy the end of this notebook, you will understand how to:\n\nStream and query oceanographic data using PelicanFS\n\nUse metadata to inform data exploration\n\nVisualize regional and depth-specific ocean data using Panel and Bokeh\n\n","type":"content","url":"/notebooks/atmosphere-llc2160-visualization#overview","position":3},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook","lvl3":"Prerequisites"},"type":"lvl3","url":"/notebooks/atmosphere-llc2160-visualization#prerequisites","position":4},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook","lvl3":"Prerequisites"},"content":"This section was inspired by \n\nthis template of the wonderful \n\nThe Turing Way Jupyter Book.\n\nConcepts\n\nImportance\n\nNotes\n\nOpenVisus\n\nHelpful\n\nRequired for multiresolution data access and streaming\n\nOceanographic data formats and interpretation\n\nHelpful\n\nUnderstanding of gridded climate/ocean data such as LLC2160\n\nPelicanFS\n\nHelpful\n\nUsed for high-throughput data access from cloud storage\n\nTime to learn: 30 minutes\n\nSystem requirements:\n\nPython packages: panel, bokeh, xmltodict, colorcet, boto3, basemap, pelicanfs, OpenVisus, openvisuspy\n\nRecommended: Python ≥ 3.8, internet access for cloud-hosted data\n\n","type":"content","url":"/notebooks/atmosphere-llc2160-visualization#prerequisites","position":5},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook","lvl2":"Step 1: Importing the libraries"},"type":"lvl2","url":"/notebooks/atmosphere-llc2160-visualization#step-1-importing-the-libraries","position":6},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook","lvl2":"Step 1: Importing the libraries"},"content":"\n\nimport numpy as np\nimport openvisuspy as ovp\nimport matplotlib.pyplot as plt\n\n","type":"content","url":"/notebooks/atmosphere-llc2160-visualization#step-1-importing-the-libraries","position":7},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook","lvl4":"The section below shows different LLC2160 fields we have available in cloud. Each field is >200TB.","lvl2":"Step 1: Importing the libraries"},"type":"lvl4","url":"/notebooks/atmosphere-llc2160-visualization#the-section-below-shows-different-llc2160-fields-we-have-available-in-cloud-each-field-is-200tb","position":8},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook","lvl4":"The section below shows different LLC2160 fields we have available in cloud. Each field is >200TB.","lvl2":"Step 1: Importing the libraries"},"content":"\n\nvariable = 'u'\nface=0 # 6 variables are available\ntimestep=1 # There are 10000 timesteps available\n\nbase_url= \"pelican://osg-htc.org/nasa/nsdf/climate3/dyamond/GEOS/\"\nvar_dir=f\"GEOS_{variable.upper()}/{variable.lower()}_face_{face}_depth_52_time_0_10269.idx\"\nvar_url=base_url+var_dir\n\n","type":"content","url":"/notebooks/atmosphere-llc2160-visualization#the-section-below-shows-different-llc2160-fields-we-have-available-in-cloud-each-field-is-200tb","position":9},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook","lvl3":"Step 2: Reading the metadata file from cloud","lvl2":"Step 1: Importing the libraries"},"type":"lvl3","url":"/notebooks/atmosphere-llc2160-visualization#step-2-reading-the-metadata-file-from-cloud","position":10},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook","lvl3":"Step 2: Reading the metadata file from cloud","lvl2":"Step 1: Importing the libraries"},"content":"In this section, you can select any variables that you can declared in the cells above and replace it inside LoadDataset. We are just reading the metadata for the dataset here.\n\ndb=ovp.LoadDataset(var_url)\nprint(f'Dimensions: {db.getLogicBox()[1][0]}*{db.getLogicBox()[1][1]}*{db.getLogicBox()[1][2]}')\nprint(f'Total Timesteps: {len(db.getTimesteps())}')\nprint(f'Field: {db.getField().name}')\nprint('Data Type: float32')\n\n","type":"content","url":"/notebooks/atmosphere-llc2160-visualization#step-2-reading-the-metadata-file-from-cloud","position":11},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook","lvl3":"Step 3:  Data Selection","lvl2":"Step 1: Importing the libraries"},"type":"lvl3","url":"/notebooks/atmosphere-llc2160-visualization#step-3-data-selection","position":12},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook","lvl3":"Step 3:  Data Selection","lvl2":"Step 1: Importing the libraries"},"content":"This section shows you how to load the data you want. You can select any timestep, region (x,y,z) you want. You can set the quality or resolution of the data as well. Higher quality means the finer(more) data. Not setting any time means first timestep available. Not setting quality means full data which takes a while to load because of the higher filesize.  Since each timestep is >30GB, I am only selecting 1 level out of 90.\n\ndata=db.db.read(time=0,z=[0,1],quality=-4) #Since each timestep is >30GB, I am only selecting 1 level out of 90.\ndata.shape\n\n","type":"content","url":"/notebooks/atmosphere-llc2160-visualization#step-3-data-selection","position":13},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook","lvl3":"Step 4:  Visualize the data","lvl2":"Step 1: Importing the libraries"},"type":"lvl3","url":"/notebooks/atmosphere-llc2160-visualization#step-4-visualize-the-data","position":14},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook","lvl3":"Step 4:  Visualize the data","lvl2":"Step 1: Importing the libraries"},"content":"We are using a simple matplotlib here, but since the data is in numpy array, it can loaded with any python modules that support numpy. Feel free to set the vmin,vmax appropriately.\n\nfig,axes=plt.subplots(1,1,figsize=(12,8))\nim= axes.imshow(data[0,:,:], aspect='auto',origin='lower',cmap='coolwarm')\ncbar = plt.colorbar(im, ax=axes)\ncbar.set_label('Temperature (deg. C)')\nplt.show()\n\n\n","type":"content","url":"/notebooks/atmosphere-llc2160-visualization#step-4-visualize-the-data","position":15},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook","lvl4":"Please reach out to Aashish Panta, Giorgio Scorzelli or Valerio Pascucci for any concerns about the notebook. Thank you!","lvl3":"Step 4:  Visualize the data","lvl2":"Step 1: Importing the libraries"},"type":"lvl4","url":"/notebooks/atmosphere-llc2160-visualization#please-reach-out-to-aashish-panta-giorgio-scorzelli-or-valerio-pascucci-for-any-concerns-about-the-notebook-thank-you","position":16},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Atmospheric Dataset Notebook","lvl4":"Please reach out to Aashish Panta, Giorgio Scorzelli or Valerio Pascucci for any concerns about the notebook. Thank you!","lvl3":"Step 4:  Visualize the data","lvl2":"Step 1: Importing the libraries"},"content":"Aashish Panta (\n\naashishpanta0@gmail​.com)\n\nGiorgio Scorzelli (\n\nscrgiorgio@gmail​.com)\n\nValerio Pascucci (\n\npascucci​.valerio@gmail​.com)","type":"content","url":"/notebooks/atmosphere-llc2160-visualization#please-reach-out-to-aashish-panta-giorgio-scorzelli-or-valerio-pascucci-for-any-concerns-about-the-notebook-thank-you","position":17},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS"},"type":"lvl1","url":"/notebooks/introduction-to-nsdf-openvisus","position":0},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS"},"content":"\n\n","type":"content","url":"/notebooks/introduction-to-nsdf-openvisus","position":1},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"type":"lvl2","url":"/notebooks/introduction-to-nsdf-openvisus#openvisus-high-performance-big-data-analysis-and-visualization","position":2},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"content":"","type":"content","url":"/notebooks/introduction-to-nsdf-openvisus#openvisus-high-performance-big-data-analysis-and-visualization","position":3},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"Overview","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"type":"lvl3","url":"/notebooks/introduction-to-nsdf-openvisus#overview","position":4},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"Overview","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"content":"OpenViSUS is an open-source framework designed for efficient management, analysis, and visualization of large-scale scientific datasets. It enables interactive exploration of petabyte-scale data on a wide range of devices, from supercomputers to commodity laptops, making big data accessible to all users.\n\n","type":"content","url":"/notebooks/introduction-to-nsdf-openvisus#overview","position":5},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"Key Features","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"type":"lvl3","url":"/notebooks/introduction-to-nsdf-openvisus#key-features","position":6},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"Key Features","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"content":"Efficient Data Storage: Uses the IDX format, which stores data in a hierarchical Z (HZ) order for cache-oblivious, progressive access.\n\nScalable Visualization: Enables interactive visualization of terabyte and petabyte datasets without requiring high-end hardware.\n\nProgressive Streaming: Optimizes network utilization with state-of-the-art compression algorithms for fast data delivery and streaming.\n\nWeb-Based Dashboards: Provides customizable dashboards for data analysis accessible from any device with an internet connection.\n\nOpen Source: Distributed under the permissive BSD license.\n\n","type":"content","url":"/notebooks/introduction-to-nsdf-openvisus#key-features","position":7},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"Data Storage: The IDX Format","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"type":"lvl3","url":"/notebooks/introduction-to-nsdf-openvisus#data-storage-the-idx-format","position":8},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"Data Storage: The IDX Format","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"content":"Hierarchical Z (HZ) Order: Data is organized to allow efficient, multi-resolution access and visualization.\n\nProgressive Access: Users can interactively explore data at different resolutions, starting with coarse overviews and refining to full detail as needed.\n\n","type":"content","url":"/notebooks/introduction-to-nsdf-openvisus#data-storage-the-idx-format","position":9},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"Data Delivery","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"type":"lvl3","url":"/notebooks/introduction-to-nsdf-openvisus#data-delivery","position":10},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"Data Delivery","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"content":"Interactive Streaming: Share and stream large datasets using simple server modules (e.g., Apache), enabling teravoxel imagery delivery.\n\nCloud and Local Access: Data can be accessed from local storage or cloud repositories, with optimized streaming for remote analysis.\n\n","type":"content","url":"/notebooks/introduction-to-nsdf-openvisus#data-delivery","position":11},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"Interactive Analysis and Visualization","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"type":"lvl3","url":"/notebooks/introduction-to-nsdf-openvisus#interactive-analysis-and-visualization","position":12},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"Interactive Analysis and Visualization","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"content":"Cross-Platform: Works on supercomputers, desktops, and laptops.\n\nScripting Support: Experiment with interactive scripting for rapid data insights.\n\nUser-Friendly Querying: Abstracts complexities of file systems and cloud services, allowing scientists to focus on analysis.\n\n","type":"content","url":"/notebooks/introduction-to-nsdf-openvisus#interactive-analysis-and-visualization","position":13},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"2026 IEEE SciVis  Contest","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"type":"lvl3","url":"/notebooks/introduction-to-nsdf-openvisus#id-2026-ieee-scivis-contest","position":14},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"2026 IEEE SciVis  Contest","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"content":"NSDF-OpenVISUS is directly supporting the 2026 IEEE SciVis Contest. This contest is held annually as part of the IEEE VIS Conference. In 2026, this contest will focus on the visualization of petascale oceanic and atmospheric climate data provided by NASA. This year’s challenge emphasizes advanced visualization methods for exploring vast climate datasets, encouraging innovative solutions that address real-world issues such as climate prediction, weather simulation, and environmental impact analysis.\n\nThe best submission wins $1000 cash prize. Find more information on the official \n\nSciVis website.\n\n","type":"content","url":"/notebooks/introduction-to-nsdf-openvisus#id-2026-ieee-scivis-contest","position":15},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"Example Use Cases","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"type":"lvl3","url":"/notebooks/introduction-to-nsdf-openvisus#example-use-cases","position":16},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"Example Use Cases","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"content":"NASA LLC2160 Data Interactive Dashboard\n\nNEX-GDDP-CMIP6 Dashboard\n\nClassroom deployment for minority-serving institutions\n\n","type":"content","url":"/notebooks/introduction-to-nsdf-openvisus#example-use-cases","position":17},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"Other Deplyments","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"type":"lvl3","url":"/notebooks/introduction-to-nsdf-openvisus#other-deplyments","position":18},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"Other Deplyments","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"content":"Cornell High Energy Synchrotron Source (CHESS)\n\nNational Center for Atmospheric Research (NCAR)\n\nNEON\n\nSOMOSPIE\n\n","type":"content","url":"/notebooks/introduction-to-nsdf-openvisus#other-deplyments","position":19},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"Getting Started","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"type":"lvl3","url":"/notebooks/introduction-to-nsdf-openvisus#getting-started","position":20},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"Getting Started","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"content":"","type":"content","url":"/notebooks/introduction-to-nsdf-openvisus#getting-started","position":21},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl4":"Installation","lvl3":"Getting Started","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"type":"lvl4","url":"/notebooks/introduction-to-nsdf-openvisus#installation","position":22},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl4":"Installation","lvl3":"Getting Started","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"content":"Install Using pip\n\npip install OpenVisus\n\nBuild from Source:\n\nClone the repository: git clone https://github.com/sci-visus/OpenVisus.git\n\nFollow instructions in the README.md and docs/compilation.md for building on your platform.\n\n","type":"content","url":"/notebooks/introduction-to-nsdf-openvisus#installation","position":23},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"References","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"type":"lvl3","url":"/notebooks/introduction-to-nsdf-openvisus#references","position":24},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl3":"References","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"content":"National Science Data Fabric\n\nOpenVisus\n\nOpenVisuspy\n\nPlease consult these papers for technical details and use cases:\n\nWeb-based Visualization and Analytics of Petascale data: Equity as a Tide that Lifts All Boats\n\nInteractive Visualization of Terascale Data in the Browser: Fact or Fiction?\n\nFast Multiresolution Reads of Massive Simulation Datasets\n\n","type":"content","url":"/notebooks/introduction-to-nsdf-openvisus#references","position":25},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl4":"Please reach out to Aashish Panta, Giorgio Scorzelli or Valerio Pascucci for any concerns about the notebook. Thank you!","lvl3":"References","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"type":"lvl4","url":"/notebooks/introduction-to-nsdf-openvisus#please-reach-out-to-aashish-panta-giorgio-scorzelli-or-valerio-pascucci-for-any-concerns-about-the-notebook-thank-you","position":26},{"hierarchy":{"lvl1":"Introduction to NSDF-OpenVISUS","lvl4":"Please reach out to Aashish Panta, Giorgio Scorzelli or Valerio Pascucci for any concerns about the notebook. Thank you!","lvl3":"References","lvl2":"OpenViSUS: High Performance Big Data Analysis and Visualization"},"content":"Aashish Panta (\n\naashishpanta0@gmail​.com)\n\nGiorgio Scorzelli (\n\nscrgiorgio@gmail​.com)\n\nValerio Pascucci (\n\npascucci​.valerio@gmail​.com)\n\n","type":"content","url":"/notebooks/introduction-to-nsdf-openvisus#please-reach-out-to-aashish-panta-giorgio-scorzelli-or-valerio-pascucci-for-any-concerns-about-the-notebook-thank-you","position":27},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook"},"type":"lvl1","url":"/notebooks/ocean-llc2160-visualization","position":0},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook"},"content":"\n\nThe DYnamics of the Atmospheric general circulation Modeled On Non-hydrostatic Domains (DYAMOND) data provides high resolution ocean circulation models, offering unprecedented detail. This dataset comprises a C1440 configuration of the Goddard Earth Observing System (GEOS) atmospheric model, with 7-km horizontal grid spacing and 72 vertical layers, coupled to a LLC2160 configuration of the Massachusetts Institute of Technology general circulation model (MITgcm) with 2–4-km grid spacing and 90 vertical levels. The C1440-LLC2160 simulation has been integrated for 14 months, starting from prescribed initial conditions on January 20, 2020.\n\n\n\n","type":"content","url":"/notebooks/ocean-llc2160-visualization","position":1},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl3":"Overview"},"type":"lvl3","url":"/notebooks/ocean-llc2160-visualization#overview","position":2},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl3":"Overview"},"content":"This notebook demonstrates how to access and visualize high-resolution ocean data from the LLC2160 dataset using OpenVisus. The data is hosted in OSDF and served using Pelican Platform and OpenVisus. You’ll learn how to read metadata from the cloud, interactively select variables, and explore regional and depth-based slices of the data.\n\nRead the metadata file from cloud\n\nData Subset\n\nVisualize the data\n\nExplore multi-resolution data for a specific region and depth\n\nBy the end of this notebook, you will understand how to:\n\nStream and query oceanographic data using PelicanFS\n\nUse metadata to inform data exploration\n\nVisualize regional and depth-specific ocean data using Panel and Bokeh\n\n\n\n","type":"content","url":"/notebooks/ocean-llc2160-visualization#overview","position":3},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl3":"Prerequisites"},"type":"lvl3","url":"/notebooks/ocean-llc2160-visualization#prerequisites","position":4},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl3":"Prerequisites"},"content":"This section was inspired by \n\nthis template of the wonderful \n\nThe Turing Way Jupyter Book.\n\nConcepts\n\nImportance\n\nNotes\n\nOpenVisus\n\nHelpful\n\nRequired for multiresolution data access and streaming\n\nOceanographic data formats and interpretation\n\nHelpful\n\nUnderstanding of gridded climate/ocean data such as LLC2160\n\nPelicanFS\n\nHelpful\n\nUsed for high-throughput data access from cloud storage\n\nTime to learn: 30 minutes\n\nSystem requirements:\n\nPython packages: panel, bokeh, xmltodict, colorcet, boto3, basemap, pelicanfs, OpenVisus, openvisuspy\n\nRecommended: Python ≥ 3.8, internet access for cloud-hosted data\n\n","type":"content","url":"/notebooks/ocean-llc2160-visualization#prerequisites","position":5},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl2":"Step 1: Importing the libraries"},"type":"lvl2","url":"/notebooks/ocean-llc2160-visualization#step-1-importing-the-libraries","position":6},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl2":"Step 1: Importing the libraries"},"content":"\n\nimport numpy as np\nimport openvisuspy as ovp\nimport matplotlib.pyplot as plt\n\n","type":"content","url":"/notebooks/ocean-llc2160-visualization#step-1-importing-the-libraries","position":7},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl4":"The section below shows different LLC2160 fields we have available in cloud. Each field is >200TB.","lvl2":"Step 1: Importing the libraries"},"type":"lvl4","url":"/notebooks/ocean-llc2160-visualization#the-section-below-shows-different-llc2160-fields-we-have-available-in-cloud-each-field-is-200tb","position":8},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl4":"The section below shows different LLC2160 fields we have available in cloud. Each field is >200TB.","lvl2":"Step 1: Importing the libraries"},"content":"\n\nvariable='salt' # options are: u,v,w,salt,theta\n\n\nbase_url= \"pelican://osg-htc.org/nasa/nsdf/climate3/dyamond/\"\nif variable==\"theta\" or variable==\"w\":\n    base_dir=f\"mit_output/llc2160_{variable}/llc2160_{variable}.idx\"\nelif variable==\"u\":\n    base_dir= \"mit_output/llc2160_arco/visus.idx\"\nelse:\n    base_dir=f\"mit_output/llc2160_{variable}/{variable}_llc2160_x_y_depth.idx\"\nvar_url=base_url+base_dir\n\n","type":"content","url":"/notebooks/ocean-llc2160-visualization#the-section-below-shows-different-llc2160-fields-we-have-available-in-cloud-each-field-is-200tb","position":9},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl3":"Step 2: Reading the metadata file from cloud","lvl2":"Step 1: Importing the libraries"},"type":"lvl3","url":"/notebooks/ocean-llc2160-visualization#step-2-reading-the-metadata-file-from-cloud","position":10},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl3":"Step 2: Reading the metadata file from cloud","lvl2":"Step 1: Importing the libraries"},"content":"In this section, you can select any variables that you can declared in the cells above and replace it inside LoadDataset. We are just reading the metadata for the dataset here.\n\ndb=ovp.LoadDataset(var_url)\nprint(f'Dimensions: {db.getLogicBox()[1][0]}*{db.getLogicBox()[1][1]}*{db.getLogicBox()[1][2]}')\nprint(f'Total Timesteps: {len(db.getTimesteps())}')\nprint(f'Field: {db.getField().name}')\nprint('Data Type: float32')\n\n","type":"content","url":"/notebooks/ocean-llc2160-visualization#step-2-reading-the-metadata-file-from-cloud","position":11},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl3":"Step 3:  Data Selection","lvl2":"Step 1: Importing the libraries"},"type":"lvl3","url":"/notebooks/ocean-llc2160-visualization#step-3-data-selection","position":12},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl3":"Step 3:  Data Selection","lvl2":"Step 1: Importing the libraries"},"content":"This section shows you how to load the data you want. You can select any timestep, region (x,y,z) you want. You can set the quality or resolution of the data as well. Higher quality means the finer(more) data. Not setting any time means first timestep available. Not setting quality means full data which takes a while to load because of the higher filesize.  Since each timestep is >30GB, I am only selecting 1 level out of 90.\n\ndata=db.db.read(time=0,z=[0,1],quality=-4) #Since each timestep is >30GB, I am only selecting 1 level out of 90.\ndata.shape\n\n","type":"content","url":"/notebooks/ocean-llc2160-visualization#step-3-data-selection","position":13},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl3":"Step 4:  Visualize the data","lvl2":"Step 1: Importing the libraries"},"type":"lvl3","url":"/notebooks/ocean-llc2160-visualization#step-4-visualize-the-data","position":14},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl3":"Step 4:  Visualize the data","lvl2":"Step 1: Importing the libraries"},"content":"We are using a simple matplotlib here, but since the data is in numpy array, it can loaded with any python modules that support numpy. Feel free to set the vmin,vmax appropriately.\n\nfig,axes=plt.subplots(1,1,figsize=(12,8))\nim= axes.imshow(data[0,:,:], aspect='auto',origin='lower',cmap='turbo')\ncbar = plt.colorbar(im, ax=axes)\ncbar.set_label('Temperature (deg. C)')\nplt.show()\n\n\n","type":"content","url":"/notebooks/ocean-llc2160-visualization#step-4-visualize-the-data","position":15},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl3":"But, what if you want to see the full data for a certain region at a certain depth?","lvl2":"Step 1: Importing the libraries"},"type":"lvl3","url":"/notebooks/ocean-llc2160-visualization#but-what-if-you-want-to-see-the-full-data-for-a-certain-region-at-a-certain-depth","position":16},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl3":"But, what if you want to see the full data for a certain region at a certain depth?","lvl2":"Step 1: Importing the libraries"},"content":"Just set the right x,y,z while reading the data. x and y are the bounding box, z is the depth/layer.\n\ndata1=db.db.read(time=1,z=[0,1],quality=-6,x=[500,2500],y=[2500,5000])\nplt.imshow(data1[0,:,:], origin='lower',cmap='turbo')\nplt.colorbar()\n\ndata1.shape #\n\n","type":"content","url":"/notebooks/ocean-llc2160-visualization#but-what-if-you-want-to-see-the-full-data-for-a-certain-region-at-a-certain-depth","position":17},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl2":"Step 5: Save the data for the region locally"},"type":"lvl2","url":"/notebooks/ocean-llc2160-visualization#step-5-save-the-data-for-the-region-locally","position":18},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl2":"Step 5: Save the data for the region locally"},"content":"You can save the data locally as you want. For example, here we are only saving the region shown above as a numpy array.\n\nnp.save('test_region2.npy', data1)\n\n","type":"content","url":"/notebooks/ocean-llc2160-visualization#step-5-save-the-data-for-the-region-locally","position":19},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl2":"Step 6: Load the locally saved region and visualize using matplotlib"},"type":"lvl2","url":"/notebooks/ocean-llc2160-visualization#step-6-load-the-locally-saved-region-and-visualize-using-matplotlib","position":20},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl2":"Step 6: Load the locally saved region and visualize using matplotlib"},"content":"\n\nlocal_data=np.load('test_region2.npy')\nplt.imshow(local_data[0,:,:], origin='lower',cmap='turbo')\nplt.colorbar()\n\n","type":"content","url":"/notebooks/ocean-llc2160-visualization#step-6-load-the-locally-saved-region-and-visualize-using-matplotlib","position":21},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl2":"Step 7: Horizontal Slicing"},"type":"lvl2","url":"/notebooks/ocean-llc2160-visualization#step-7-horizontal-slicing","position":22},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl2":"Step 7: Horizontal Slicing"},"content":"\n\ndata1=db.db.read(time=1,x=[500,2500],y=[5100,5101])\ndata1.shape\n\n\nplt.figure(figsize=(14,8))\nplt.imshow(data1[:,0,:],cmap='turbo')\n# plt.colorbar()\n\n","type":"content","url":"/notebooks/ocean-llc2160-visualization#step-7-horizontal-slicing","position":23},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl4":"Please reach out to Aashish Panta, Giorgio Scorzelli or Valerio Pascucci for any concerns about the notebook. Thank you!","lvl2":"Step 7: Horizontal Slicing"},"type":"lvl4","url":"/notebooks/ocean-llc2160-visualization#please-reach-out-to-aashish-panta-giorgio-scorzelli-or-valerio-pascucci-for-any-concerns-about-the-notebook-thank-you","position":24},{"hierarchy":{"lvl1":"DYAMOND LLC2160 Ocean Dataset Notebook","lvl4":"Please reach out to Aashish Panta, Giorgio Scorzelli or Valerio Pascucci for any concerns about the notebook. Thank you!","lvl2":"Step 7: Horizontal Slicing"},"content":"Aashish Panta (\n\naashishpanta0@gmail​.com)\n\nGiorgio Scorzelli (\n\nscrgiorgio@gmail​.com)\n\nValerio Pascucci (\n\npascucci​.valerio@gmail​.com)","type":"content","url":"/notebooks/ocean-llc2160-visualization#please-reach-out-to-aashish-panta-giorgio-scorzelli-or-valerio-pascucci-for-any-concerns-about-the-notebook-thank-you","position":25},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook"},"type":"lvl1","url":"/notebooks/ocean-llc4320-visualization","position":0},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook"},"content":"\n\nLLC4320, a product of \n\nEstimating the Circulation and Climate of the Ocean (ECCO) project, is the product of a 14-month simulation of ocean circulation and dynamics using MITgcm model. This simulation is similar to the ocean portion of the DYAMOND coupled simulation but was run with half the horizontal grid spacing (4\\times the cell count) and with ocean surface boundary values derived from observations and physical models. The model output has five 3D and thirteen 2D fields, including temperature, salinity, three velocity components, sea ice, and radiation. This massive dataset is 2.8 PB.\n\n","type":"content","url":"/notebooks/ocean-llc4320-visualization","position":1},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl3":"Overview"},"type":"lvl3","url":"/notebooks/ocean-llc4320-visualization#overview","position":2},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl3":"Overview"},"content":"This notebook demonstrates how to access and visualize high-resolution ocean data from the LLC4320 dataset using OpenVisus. The data is hosted in OSDF and served using Pelican Platform and OpenVisus. You’ll learn how to read metadata from the cloud, interactively select variables, and explore regional and depth-based slices of the data.\n\nRead the metadata file from cloud\n\nData Subset\n\nVisualize the data\n\nExplore multi-resolution data for a specific region and depth\n\nBy the end of this notebook, you will understand how to:\n\nStream and query oceanographic data using PelicanFS\n\nUse metadata to inform data exploration\n\nVisualize regional and depth-specific ocean data using Panel and Bokeh\n\n","type":"content","url":"/notebooks/ocean-llc4320-visualization#overview","position":3},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl3":"Prerequisites"},"type":"lvl3","url":"/notebooks/ocean-llc4320-visualization#prerequisites","position":4},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl3":"Prerequisites"},"content":"This section was inspired by \n\nthis template of the wonderful \n\nThe Turing Way Jupyter Book.\n\nConcepts\n\nImportance\n\nNotes\n\nOpenVisus\n\nHelpful\n\nRequired for multiresolution data access and streaming\n\nOceanographic data formats and interpretation\n\nHelpful\n\nUnderstanding of gridded climate/ocean data such as LLC2160\n\nPelicanFS\n\nHelpful\n\nUsed for high-throughput data access from cloud storage\n\nTime to learn: 30 minutes\n\nSystem requirements:\n\nPython packages: panel, bokeh, xmltodict, colorcet, boto3, basemap, pelicanfs, OpenVisus, openvisuspy\n\nRecommended: Python ≥ 3.8, internet access for cloud-hosted data\n\n","type":"content","url":"/notebooks/ocean-llc4320-visualization#prerequisites","position":5},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl2":"Step 1: Importing the libraries"},"type":"lvl2","url":"/notebooks/ocean-llc4320-visualization#step-1-importing-the-libraries","position":6},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl2":"Step 1: Importing the libraries"},"content":"\n\nimport numpy as np\nimport openvisuspy as ovp\nimport matplotlib.pyplot as plt\n\n","type":"content","url":"/notebooks/ocean-llc4320-visualization#step-1-importing-the-libraries","position":7},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl4":"The section below shows different LLC4320 fields we have available in cloud. Each field is >400TB.","lvl2":"Step 1: Importing the libraries"},"type":"lvl4","url":"/notebooks/ocean-llc4320-visualization#the-section-below-shows-different-llc4320-fields-we-have-available-in-cloud-each-field-is-400tb","position":8},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl4":"The section below shows different LLC4320 fields we have available in cloud. Each field is >400TB.","lvl2":"Step 1: Importing the libraries"},"content":"\n\ntemperature=\"pelican://osg-htc.org/nasa/nsdf/climate1/llc4320/idx/theta/theta_llc4320_x_y_depth.idx\"\n\nsalinity=\"pelican://osg-htc.org/nasa/nsdf/climate1/llc4320/idx/salt/salt_llc4320_x_y_depth.idx\"\n\nvertical_velocity=\"pelican://osg-htc.org/nasa/nsdf/climate2/llc4320/idx/w/w_llc4320_x_y_depth.idx\"\n\n","type":"content","url":"/notebooks/ocean-llc4320-visualization#the-section-below-shows-different-llc4320-fields-we-have-available-in-cloud-each-field-is-400tb","position":9},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl3":"Step 2: Reading the metadata file from cloud","lvl2":"Step 1: Importing the libraries"},"type":"lvl3","url":"/notebooks/ocean-llc4320-visualization#step-2-reading-the-metadata-file-from-cloud","position":10},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl3":"Step 2: Reading the metadata file from cloud","lvl2":"Step 1: Importing the libraries"},"content":"In this section, you can select any variables that you can declared in the cells above and replace it inside LoadDataset. We are just reading the metadata for the dataset here.\n\ndb=ovp.LoadDataset(temperature)\nprint(f'Dimensions: {db.getLogicBox()[1][0]}*{db.getLogicBox()[1][1]}*{db.getLogicBox()[1][2]}')\nprint(f'Total Timesteps: {len(db.getTimesteps())}')\nprint(f'Field: {db.getField().name}')\nprint('Data Type: float32')\n\n","type":"content","url":"/notebooks/ocean-llc4320-visualization#step-2-reading-the-metadata-file-from-cloud","position":11},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl3":"Step 3:  Data Selection","lvl2":"Step 1: Importing the libraries"},"type":"lvl3","url":"/notebooks/ocean-llc4320-visualization#step-3-data-selection","position":12},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl3":"Step 3:  Data Selection","lvl2":"Step 1: Importing the libraries"},"content":"This section shows you how to load the data you want. You can select any timestep, region (x,y,z) you want. You can set the quality or resolution of the data as well. Higher quality means the finer(more) data. Not setting any time means first timestep available. Not setting quality means full data which takes a while to load because of the higher filesize.  Since each timestep is >30GB, I am only selecting 1 level out of 90.\n\ndata=db.db.read(time=0,z=[0,1],quality=-4) #Since each timestep is >30GB, I am only selecting 1 level out of 90.\ndata.shape\n\n","type":"content","url":"/notebooks/ocean-llc4320-visualization#step-3-data-selection","position":13},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl3":"Step 4:  Visualize the data","lvl2":"Step 1: Importing the libraries"},"type":"lvl3","url":"/notebooks/ocean-llc4320-visualization#step-4-visualize-the-data","position":14},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl3":"Step 4:  Visualize the data","lvl2":"Step 1: Importing the libraries"},"content":"We are using a simple matplotlib here, but since the data is in numpy array, it can loaded with any python modules that support numpy. Feel free to set the vmin,vmax appropriately.\n\nfig,axes=plt.subplots(1,1,figsize=(12,8))\nim= axes.imshow(data[0,:,:], aspect='auto',origin='lower',cmap='turbo')\ncbar = plt.colorbar(im, ax=axes)\ncbar.set_label('Temperature (deg. C)')\nplt.show()\n\n\n","type":"content","url":"/notebooks/ocean-llc4320-visualization#step-4-visualize-the-data","position":15},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl3":"But, what if you want to see the full data for a certain region at a certain depth?","lvl2":"Step 1: Importing the libraries"},"type":"lvl3","url":"/notebooks/ocean-llc4320-visualization#but-what-if-you-want-to-see-the-full-data-for-a-certain-region-at-a-certain-depth","position":16},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl3":"But, what if you want to see the full data for a certain region at a certain depth?","lvl2":"Step 1: Importing the libraries"},"content":"Just set the right x,y,z while reading the data. x and y are the bounding box, z is the depth/layer.\n\ndata1=db.db.read(time=1,z=[0,1],quality=-6,x=[500,2500],y=[8500,11000])\nplt.imshow(data1[0,:,:], origin='lower',cmap='turbo')\nplt.colorbar()\n\ndata1.shape #\n\n","type":"content","url":"/notebooks/ocean-llc4320-visualization#but-what-if-you-want-to-see-the-full-data-for-a-certain-region-at-a-certain-depth","position":17},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl2":"Step 5: Save the data for the region locally"},"type":"lvl2","url":"/notebooks/ocean-llc4320-visualization#step-5-save-the-data-for-the-region-locally","position":18},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl2":"Step 5: Save the data for the region locally"},"content":"You can save the data locally as you want. For example, here we are only saving the region shown above as a numpy array.\n\nnp.save('test_region.npy', data1)\n\n","type":"content","url":"/notebooks/ocean-llc4320-visualization#step-5-save-the-data-for-the-region-locally","position":19},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl2":"Step 6: Load the locally saved region and visualize using matplotlib"},"type":"lvl2","url":"/notebooks/ocean-llc4320-visualization#step-6-load-the-locally-saved-region-and-visualize-using-matplotlib","position":20},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl2":"Step 6: Load the locally saved region and visualize using matplotlib"},"content":"\n\nlocal_data=np.load('test_region.npy')\nplt.imshow(local_data[0,:,:], origin='lower',cmap='turbo')\nplt.colorbar()\n\n","type":"content","url":"/notebooks/ocean-llc4320-visualization#step-6-load-the-locally-saved-region-and-visualize-using-matplotlib","position":21},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl2":"Step 7: Horizontal Slicing"},"type":"lvl2","url":"/notebooks/ocean-llc4320-visualization#step-7-horizontal-slicing","position":22},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl2":"Step 7: Horizontal Slicing"},"content":"\n\ndata1=db.db.read(time=1,x=[500,2500],y=[10500,10501])\ndata1.shape\n\n\nplt.figure(figsize=(14,8))\nplt.imshow(data1[:,0,:],cmap='turbo')\n# plt.colorbar()\n\n","type":"content","url":"/notebooks/ocean-llc4320-visualization#step-7-horizontal-slicing","position":23},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl4":"Please reach out to Aashish Panta, Giorgio Scorzelli or Valerio Pascucci for any concerns about the notebook. Thank you!","lvl2":"Step 7: Horizontal Slicing"},"type":"lvl4","url":"/notebooks/ocean-llc4320-visualization#please-reach-out-to-aashish-panta-giorgio-scorzelli-or-valerio-pascucci-for-any-concerns-about-the-notebook-thank-you","position":24},{"hierarchy":{"lvl1":"ECCO LLC4320 Ocean Dataset Notebook","lvl4":"Please reach out to Aashish Panta, Giorgio Scorzelli or Valerio Pascucci for any concerns about the notebook. Thank you!","lvl2":"Step 7: Horizontal Slicing"},"content":"Aashish Panta (\n\naashishpanta0@gmail​.com)\n\nGiorgio Scorzelli (\n\nscrgiorgio@gmail​.com)\n\nValerio Pascucci (\n\npascucci​.valerio@gmail​.com)","type":"content","url":"/notebooks/ocean-llc4320-visualization#please-reach-out-to-aashish-panta-giorgio-scorzelli-or-valerio-pascucci-for-any-concerns-about-the-notebook-thank-you","position":25},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"type":"lvl1","url":"/notebooks/how-to-cite","position":0},{"hierarchy":{"lvl1":"How to Cite This Cookbook"},"content":"The material in this Project Pythia Cookbook is licensed for free and open consumption and reuse. All code is served under \n\nApache 2.0, while all non-code content is licensed under \n\nCreative Commons BY 4.0 (CC BY 4.0). Effectively, this means you are free to share and adapt this material so long as you give appropriate credit to the Cookbook authors and the Project Pythia community.\n\nThe source code for the book is \n\nreleased on GitHub and archived on Zenodo. This DOI will always resolve to the latest release of the book source:\n\n","type":"content","url":"/notebooks/how-to-cite","position":1},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"type":"lvl1","url":"/notebooks/notebook-template","position":0},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"content":"Let’s start here! If you can directly link to an image relevant to your notebook, such as \n\ncanonical logos, do so here at the top of your notebook. You can do this with MyST Markdown syntax, outlined in \n\nthis MyST guide, or you edit this cell to see a demonstration. Be sure to include alt text for any embedded images to make your content more accessible.\n\nNext, title your notebook appropriately with a top-level Markdown header, # (see the very first cell above). Do not use this level header anywhere else in the notebook. Our book build process will use this title in the navbar, table of contents, etc. Keep it short, keep it descriptive.\n\nFollow this with a --- cell to visually distinguish the transition to the prerequisites section.\n\n\n\n","type":"content","url":"/notebooks/notebook-template","position":1},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/notebook-template#overview","position":2},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Overview"},"content":"If you have an introductory paragraph, lead with it here! Keep it short and tied to your material, then be sure to continue into the required list of topics below,\n\nThis is a numbered list of the specific topics\n\nThese should map approximately to your main sections of content\n\nOr each second-level, ##, header in your notebook\n\nKeep the size and scope of your notebook in check\n\nAnd be sure to let the reader know up front the important concepts they’ll be leaving with\n\n","type":"content","url":"/notebooks/notebook-template#overview","position":3},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/notebook-template#prerequisites","position":4},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Prerequisites"},"content":"This section was inspired by \n\nthis template of the wonderful \n\nThe Turing Way Jupyter Book.\n\nFollowing your overview, tell your reader what concepts, packages, or other background information they’ll need before learning your material. Tie this explicitly with links to other pages here in Foundations or to relevant external resources. Remove this body text, then populate the Markdown table, denoted in this cell with | vertical brackets, below, and fill out the information following. In this table, lay out prerequisite concepts by explicitly linking to other Foundations material or external resources, or describe generally helpful concepts.\n\nLabel the importance of each concept explicitly as helpful/necessary.\n\nConcepts\n\nImportance\n\nNotes\n\nIntro to Cartopy\n\nNecessary\n\n\n\nUnderstanding of NetCDF\n\nHelpful\n\nFamiliarity with metadata structure\n\nProject management\n\nHelpful\n\n\n\nTime to learn: estimate in minutes. For a rough idea, use 5 mins per subsection, 10 if longer; add these up for a total. Safer to round up and overestimate.\n\nSystem requirements:\n\nPopulate with any system, version, or non-Python software requirements if necessary\n\nOtherwise use the concepts table above and the Imports section below to describe required packages as necessary\n\nIf no extra requirements, remove the System requirements point altogether\n\n\n\n","type":"content","url":"/notebooks/notebook-template#prerequisites","position":5},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/notebook-template#imports","position":6},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Imports"},"content":"Begin your body of content with another --- divider before continuing into this section, then remove this body text and populate the following code cell with all necessary Python imports up-front:\n\nimport sys\n\n","type":"content","url":"/notebooks/notebook-template#imports","position":7},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your first content section"},"type":"lvl2","url":"/notebooks/notebook-template#your-first-content-section","position":8},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your first content section"},"content":"\n\nThis is where you begin your first section of material, loosely tied to your objectives stated up front. Tie together your notebook as a narrative, with interspersed Markdown text, images, and more as necessary,\n\n# as well as any and all of your code cells\nprint(\"Hello world!\")\n\n","type":"content","url":"/notebooks/notebook-template#your-first-content-section","position":9},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A content subsection","lvl2":"Your first content section"},"type":"lvl3","url":"/notebooks/notebook-template#a-content-subsection","position":10},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A content subsection","lvl2":"Your first content section"},"content":"Divide and conquer your objectives with Markdown subsections, which will populate the helpful navbar in Jupyter Lab and here on the Jupyter Book!\n\n# some subsection code\na = [1, 2, 3, 4, 5]\n[i + 2 for i in a]\n\n","type":"content","url":"/notebooks/notebook-template#a-content-subsection","position":11},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Another content subsection","lvl2":"Your first content section"},"type":"lvl3","url":"/notebooks/notebook-template#another-content-subsection","position":12},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Another content subsection","lvl2":"Your first content section"},"content":"Keep up the good work! A note, try to avoid using code comments as narrative, and instead let them only exist as brief clarifications where necessary.\n\n","type":"content","url":"/notebooks/notebook-template#another-content-subsection","position":13},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your second content section"},"type":"lvl2","url":"/notebooks/notebook-template#your-second-content-section","position":14},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your second content section"},"content":"Here we can move on to our second objective, and we can demonstrate...\n\n","type":"content","url":"/notebooks/notebook-template#your-second-content-section","position":15},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl3","url":"/notebooks/notebook-template#a-subsection-to-the-second-section","position":16},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/notebook-template#a-subsection-to-the-second-section","position":17},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl4","url":"/notebooks/notebook-template#a-quick-demonstration","position":18},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/notebook-template#a-quick-demonstration","position":19},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl5","url":"/notebooks/notebook-template#of-further-and-further","position":20},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/notebook-template#of-further-and-further","position":21},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl6","url":"/notebooks/notebook-template#header-levels","position":22},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"\n\nas well as m = a * t / h text! Similarly, you have access to other \\LaTeX equation \n\nfunctionality via MathJax:\\begin{align}\n\\dot{x} & = \\sigma(y-x) \\\\\n\\dot{y} & = \\rho x - y - xz \\\\\n\\dot{z} & = -\\beta z + xy\n\\end{align}\n\nCheck out \n\nany number of helpful Markdown resources for further customizing your notebooks and the \n\nMyST Syntax Overview for MyST-specific formatting information. Don’t hesitate to ask questions if you have problems getting it to look just right.\n\n","type":"content","url":"/notebooks/notebook-template#header-levels","position":23},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Last Section"},"type":"lvl2","url":"/notebooks/notebook-template#last-section","position":24},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Last Section"},"content":"You can add \n\nadmonitions using MyST syntax:\n\nNote\n\nYour relevant information here!\n\nSome other admonitions you can put in (\n\nthere are 10 total):\n\nHint\n\nA helpful hint.\n\nWarning\n\nBe careful!\n\nDanger\n\nScary stuff be here.\n\nWe also suggest checking out Jupyter Book’s \n\nbrief demonstration on adding cell tags to your cells in Jupyter Notebook, Lab, or manually. Using these cell tags can allow you to \n\ncustomize how your code content is displayed and even \n\ndemonstrate errors without altogether crashing our loyal army of machines!\n\n\n\n","type":"content","url":"/notebooks/notebook-template#last-section","position":25},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/notebook-template#summary","position":26},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Summary"},"content":"Add one final --- marking the end of your body of content, and then conclude with a brief single paragraph summarizing at a high level the key pieces that were learned and how they tied to your objectives. Look to reiterate what the most important takeaways were.","type":"content","url":"/notebooks/notebook-template#summary","position":27},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/notebook-template#whats-next","position":28},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"What’s next?","lvl2":"Summary"},"content":"Let Jupyter book tie this to the next (sequential) piece of content that people could move on to down below and in the sidebar. However, if this page uniquely enables your reader to tackle other nonsequential concepts throughout this book, or even external content, link to it here!\n\n","type":"content","url":"/notebooks/notebook-template#whats-next","position":29},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/notebook-template#resources-and-references","position":30},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Resources and references"},"content":"Finally, be rigorous in your citations and references as necessary. Give credit where credit is due. Also, feel free to link to relevant external material, further reading, documentation, etc. Then you’re done! Give yourself a quick review, a high five, and send us a pull request. A few final notes:\n\nKernel > Restart Kernel and Run All Cells... to confirm that your notebook will cleanly run from start to finish\n\nKernel > Restart Kernel and Clear All Outputs... before committing your notebook, our machines will do the heavy lifting\n\nTake credit! Provide author contact information if you’d like; if so, consider adding information here at the bottom of your notebook\n\nGive credit! Attribute appropriate authorship for referenced code, information, images, etc.\n\nOnly include what you’re legally allowed: no copyright infringement or plagiarism\n\nThank you for your contribution!","type":"content","url":"/notebooks/notebook-template#resources-and-references","position":31},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"type":"lvl1","url":"/notebooks/notebook-template","position":0},{"hierarchy":{"lvl1":"Project Pythia Notebook Template"},"content":"Let’s start here! If you can directly link to an image relevant to your notebook, such as \n\ncanonical logos, do so here at the top of your notebook. You can do this with MyST Markdown syntax, outlined in \n\nthis MyST guide, or you edit this cell to see a demonstration. Be sure to include alt text for any embedded images to make your content more accessible.\n\nNext, title your notebook appropriately with a top-level Markdown header, # (see the very first cell above). Do not use this level header anywhere else in the notebook. Our book build process will use this title in the navbar, table of contents, etc. Keep it short, keep it descriptive.\n\nFollow this with a --- cell to visually distinguish the transition to the prerequisites section.\n\n\n\n","type":"content","url":"/notebooks/notebook-template","position":1},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Overview"},"type":"lvl2","url":"/notebooks/notebook-template#overview","position":2},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Overview"},"content":"If you have an introductory paragraph, lead with it here! Keep it short and tied to your material, then be sure to continue into the required list of topics below,\n\nThis is a numbered list of the specific topics\n\nThese should map approximately to your main sections of content\n\nOr each second-level, ##, header in your notebook\n\nKeep the size and scope of your notebook in check\n\nAnd be sure to let the reader know up front the important concepts they’ll be leaving with\n\n","type":"content","url":"/notebooks/notebook-template#overview","position":3},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Prerequisites"},"type":"lvl2","url":"/notebooks/notebook-template#prerequisites","position":4},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Prerequisites"},"content":"This section was inspired by \n\nthis template of the wonderful \n\nThe Turing Way Jupyter Book.\n\nFollowing your overview, tell your reader what concepts, packages, or other background information they’ll need before learning your material. Tie this explicitly with links to other pages here in Foundations or to relevant external resources. Remove this body text, then populate the Markdown table, denoted in this cell with | vertical brackets, below, and fill out the information following. In this table, lay out prerequisite concepts by explicitly linking to other Foundations material or external resources, or describe generally helpful concepts.\n\nLabel the importance of each concept explicitly as helpful/necessary.\n\nConcepts\n\nImportance\n\nNotes\n\nIntro to Cartopy\n\nNecessary\n\n\n\nUnderstanding of NetCDF\n\nHelpful\n\nFamiliarity with metadata structure\n\nProject management\n\nHelpful\n\n\n\nTime to learn: estimate in minutes. For a rough idea, use 5 mins per subsection, 10 if longer; add these up for a total. Safer to round up and overestimate.\n\nSystem requirements:\n\nPopulate with any system, version, or non-Python software requirements if necessary\n\nOtherwise use the concepts table above and the Imports section below to describe required packages as necessary\n\nIf no extra requirements, remove the System requirements point altogether\n\n\n\n","type":"content","url":"/notebooks/notebook-template#prerequisites","position":5},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Imports"},"type":"lvl2","url":"/notebooks/notebook-template#imports","position":6},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Imports"},"content":"Begin your body of content with another --- divider before continuing into this section, then remove this body text and populate the following code cell with all necessary Python imports up-front:\n\nimport sys\n\n","type":"content","url":"/notebooks/notebook-template#imports","position":7},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your first content section"},"type":"lvl2","url":"/notebooks/notebook-template#your-first-content-section","position":8},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your first content section"},"content":"\n\nThis is where you begin your first section of material, loosely tied to your objectives stated up front. Tie together your notebook as a narrative, with interspersed Markdown text, images, and more as necessary,\n\n# as well as any and all of your code cells\nprint(\"Hello world!\")\n\n","type":"content","url":"/notebooks/notebook-template#your-first-content-section","position":9},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A content subsection","lvl2":"Your first content section"},"type":"lvl3","url":"/notebooks/notebook-template#a-content-subsection","position":10},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A content subsection","lvl2":"Your first content section"},"content":"Divide and conquer your objectives with Markdown subsections, which will populate the helpful navbar in Jupyter Lab and here on the Jupyter Book!\n\n# some subsection code\na = [1, 2, 3, 4, 5]\n[i + 2 for i in a]\n\n","type":"content","url":"/notebooks/notebook-template#a-content-subsection","position":11},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Another content subsection","lvl2":"Your first content section"},"type":"lvl3","url":"/notebooks/notebook-template#another-content-subsection","position":12},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"Another content subsection","lvl2":"Your first content section"},"content":"Keep up the good work! A note, try to avoid using code comments as narrative, and instead let them only exist as brief clarifications where necessary.\n\n","type":"content","url":"/notebooks/notebook-template#another-content-subsection","position":13},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your second content section"},"type":"lvl2","url":"/notebooks/notebook-template#your-second-content-section","position":14},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Your second content section"},"content":"Here we can move on to our second objective, and we can demonstrate...\n\n","type":"content","url":"/notebooks/notebook-template#your-second-content-section","position":15},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl3","url":"/notebooks/notebook-template#a-subsection-to-the-second-section","position":16},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/notebook-template#a-subsection-to-the-second-section","position":17},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl4","url":"/notebooks/notebook-template#a-quick-demonstration","position":18},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/notebook-template#a-quick-demonstration","position":19},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl5","url":"/notebooks/notebook-template#of-further-and-further","position":20},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"","type":"content","url":"/notebooks/notebook-template#of-further-and-further","position":21},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"type":"lvl6","url":"/notebooks/notebook-template#header-levels","position":22},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl6":"header levels","lvl5":"of further and further","lvl4":"a quick demonstration","lvl3":"A subsection to the second section","lvl2":"Your second content section"},"content":"\n\nas well as m = a * t / h text! Similarly, you have access to other \\LaTeX equation \n\nfunctionality via MathJax:\\begin{align}\n\\dot{x} & = \\sigma(y-x) \\\\\n\\dot{y} & = \\rho x - y - xz \\\\\n\\dot{z} & = -\\beta z + xy\n\\end{align}\n\nCheck out \n\nany number of helpful Markdown resources for further customizing your notebooks and the \n\nMyST Syntax Overview for MyST-specific formatting information. Don’t hesitate to ask questions if you have problems getting it to look just right.\n\n","type":"content","url":"/notebooks/notebook-template#header-levels","position":23},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Last Section"},"type":"lvl2","url":"/notebooks/notebook-template#last-section","position":24},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Last Section"},"content":"You can add \n\nadmonitions using MyST syntax:\n\nNote\n\nYour relevant information here!\n\nSome other admonitions you can put in (\n\nthere are 10 total):\n\nHint\n\nA helpful hint.\n\nWarning\n\nBe careful!\n\nDanger\n\nScary stuff be here.\n\nWe also suggest checking out Jupyter Book’s \n\nbrief demonstration on adding cell tags to your cells in Jupyter Notebook, Lab, or manually. Using these cell tags can allow you to \n\ncustomize how your code content is displayed and even \n\ndemonstrate errors without altogether crashing our loyal army of machines!\n\n\n\n","type":"content","url":"/notebooks/notebook-template#last-section","position":25},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Summary"},"type":"lvl2","url":"/notebooks/notebook-template#summary","position":26},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Summary"},"content":"Add one final --- marking the end of your body of content, and then conclude with a brief single paragraph summarizing at a high level the key pieces that were learned and how they tied to your objectives. Look to reiterate what the most important takeaways were.","type":"content","url":"/notebooks/notebook-template#summary","position":27},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"What’s next?","lvl2":"Summary"},"type":"lvl3","url":"/notebooks/notebook-template#whats-next","position":28},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl3":"What’s next?","lvl2":"Summary"},"content":"Let Jupyter book tie this to the next (sequential) piece of content that people could move on to down below and in the sidebar. However, if this page uniquely enables your reader to tackle other nonsequential concepts throughout this book, or even external content, link to it here!\n\n","type":"content","url":"/notebooks/notebook-template#whats-next","position":29},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Resources and references"},"type":"lvl2","url":"/notebooks/notebook-template#resources-and-references","position":30},{"hierarchy":{"lvl1":"Project Pythia Notebook Template","lvl2":"Resources and references"},"content":"Finally, be rigorous in your citations and references as necessary. Give credit where credit is due. Also, feel free to link to relevant external material, further reading, documentation, etc. Then you’re done! Give yourself a quick review, a high five, and send us a pull request. A few final notes:\n\nKernel > Restart Kernel and Run All Cells... to confirm that your notebook will cleanly run from start to finish\n\nKernel > Restart Kernel and Clear All Outputs... before committing your notebook, our machines will do the heavy lifting\n\nTake credit! Provide author contact information if you’d like; if so, consider adding information here at the bottom of your notebook\n\nGive credit! Attribute appropriate authorship for referenced code, information, images, etc.\n\nOnly include what you’re legally allowed: no copyright infringement or plagiarism\n\nThank you for your contribution!","type":"content","url":"/notebooks/notebook-template#resources-and-references","position":31}]}